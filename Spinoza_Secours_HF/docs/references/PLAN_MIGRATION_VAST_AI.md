# Plan de Migration Complet - Spinoza Secours vers Vast.ai

**Date :** Janvier 2025  
**Projet :** Spinoza Secours HF  
**Source :** Colab + ngrok  
**Destination :** Vast.ai (RTX 3090 ou RTX 4090)  
**Budget :** 
- RTX 3090 : ~$0.20-0.40/h (v√©rifier tarifs actuels)
- **RTX 4090 : $0.29/h** ‚úÖ (tarif v√©rifi√© Janvier 2025)

---

## üìã Table des Mati√®res

1. [Vue d'Ensemble](#vue-densemble)
2. [Pr√©requis](#pr√©requis)
3. [√âtape 1 : Pr√©paration](#√©tape-1--pr√©paration)
4. [√âtape 2 : Cr√©ation Compte Vast.ai](#√©tape-2--cr√©ation-compte-vastai)
5. [√âtape 3 : Configuration Instance](#√©tape-3--configuration-instance)
6. [√âtape 4 : D√©ploiement](#√©tape-4--d√©ploiement)
7. [√âtape 5 : Tests](#√©tape-5--tests)
8. [√âtape 6 : Mise √† Jour Frontend](#√©tape-6--mise-√†-jour-frontend)
9. [√âtape 7 : Validation Compl√®te](#√©tape-7--validation-compl√®te)
10. [S√©curit√© et Bonnes Pratiques](#s√©curit√©-et-bonnes-pratiques)
11. [Maintenance et Monitoring](#maintenance-et-monitoring)
12. [Troubleshooting](#troubleshooting)
13. [Proc√©dures Post-D√©ploiement](#proc√©dures-post-d√©ploiement)
14. [Checklist Compl√®te](#checklist-compl√®te)

---

## üìç Quick Reference - Lignes Critiques

| Fichier | Ligne | Contenu | Action |
|---------|-------|---------|--------|
| `Backend/app_runpod.py` | 543 | CORS `allow_origins=["*"]` | ‚ö†Ô∏è **RESTREINDRE** en production |
| `Backend/app_runpod.py` | 619-624 | `uvicorn.run()` avec `log_level="info"` | ‚úÖ OK |
| `Frontend/index_spinoza.html` | 127 | `API_BASE_URL` | ‚ö†Ô∏è **METTRE √Ä JOUR** avec URL Vast.ai |
| `Backend/app_runpod.py` | 401, 449, 489 | `max_new_tokens` (optimisation latence) | ‚ö†Ô∏è Peut √™tre r√©duit si besoin |
| `Backend/requirements.runpod.txt` | 7 | `pydantic>=2.5.0` | ‚úÖ V2 (utiliser `field_validator`) |

---

## üéØ Vue d'Ensemble

### Architecture Actuelle (Colab)

```
Frontend (fjdaz.com)
    ‚Üì
Colab + ngrok (URL temporaire)
    ‚Üì
FastAPI + Mistral 7B + LoRA
```

**Probl√®mes :**
- URL ngrok change √† chaque session
- Instabilit√© Colab (timeout, limitations)
- N√©cessite red√©marrage manuel
- Pas de contr√¥le sur l'infrastructure

### Architecture Cible (Vast.ai)

```
Frontend (fjdaz.com)
    ‚Üì
Vast.ai (URL fixe)
    ‚Üì
Docker Container (FastAPI + Mistral 7B + LoRA)
```

**Avantages :**
- URL fixe et stable
- Contr√¥le total sur l'infrastructure
- Pay-per-use (√©conomique pour usage ponctuel)
- Performance sup√©rieure (RTX 3090 vs T4)

### Co√ªts Compar√©s

| Plateforme | GPU | Co√ªt/heure | Co√ªt 3h d√©mo | D√©p√¥t |
|------------|-----|------------|--------------|-------|
| **Colab** | T4 | Gratuit* | $0 | $0 |
| **Vast.ai** | RTX 3090 | $0.20-0.40 | $0.60-1.20 | $0 ‚úÖ |
| **Vast.ai** | **RTX 4090** | **$0.29** ‚úÖ | **$0.87** | **$0** ‚úÖ |

*Colab : Gratuit mais instable, limitations, timeout

---

## üìã Pr√©requis

### 1. Compte Vast.ai

**Lien :** https://vast.ai/

**√âtapes :**
1. Aller sur https://vast.ai/
2. Cliquer sur **"Sign Up"** ou **"Create Account"**
3. Remplir le formulaire (email, mot de passe)
4. V√©rifier l'email
5. Se connecter

**Note :** G√©n√©ralement pas de d√©p√¥t minimum requis ‚úÖ

### 2. Token Hugging Face

**Lien :** https://huggingface.co/settings/tokens

**√âtapes :**
1. Aller sur https://huggingface.co/
2. Se connecter ou cr√©er un compte
3. Aller dans **Settings** ‚Üí **Access Tokens** : https://huggingface.co/settings/tokens
4. Cliquer sur **"New token"**
5. Nom : `spinoza-secours-vast-ai`
6. Type : **Read** (suffisant pour t√©l√©charger les mod√®les)
7. Cliquer sur **"Generate token"**
8. **Copier le token** (il ne sera plus visible apr√®s)

**Mod√®les n√©cessaires :**
- Base : `mistralai/Mistral-7B-Instruct-v0.2` (public)
- LoRA : `FJDaz/mistral-7b-philosophes-lora` (peut n√©cessiter le token)

### 3. GitHub (Optionnel mais Recommand√©)

**Lien :** https://github.com/

**Si d√©ploiement depuis GitHub :**
1. Cr√©er un d√©p√¥t GitHub (ou utiliser existant)
2. Pousser les fichiers suivants :
   - `Backend/Dockerfile.runpod`
   - `Backend/app_runpod.py`
   - `Backend/requirements.runpod.txt`

**Lien d√©p√¥t actuel :** https://github.com/FJDaz/Spinoza_secours (√† v√©rifier)

### 4. Fichiers Locaux

V√©rifier que vous avez acc√®s aux fichiers suivants :
- `Backend/Dockerfile.runpod`
- `Backend/app_runpod.py`
- `Backend/requirements.runpod.txt`
- `Frontend/index_spinoza.html`

---

## üöÄ √âtape 1 : Pr√©paration

### 1.1 V√©rifier les Fichiers

**Localisation :** `/Users/francois-jeandazin/bergsonAndFriends/Spinoza_Secours_HF/Backend/`

**Fichiers requis :**
- ‚úÖ `Dockerfile.runpod` - Dockerfile pour Vast.ai
- ‚úÖ `app_runpod.py` - Application FastAPI compl√®te
- ‚úÖ `requirements.runpod.txt` - D√©pendances Python

**V√©rification :**
```bash
cd /Users/francois-jeandazin/bergsonAndFriends/Spinoza_Secours_HF/Backend/
ls -la Dockerfile.runpod app_runpod.py requirements.runpod.txt
```

### 1.2 Pr√©parer le Token Hugging Face

**Action :** Copier le token Hugging Face obtenu √† l'√©tape Pr√©requis #2

**Format :** `hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`

**Stockage temporaire :** Noter dans un endroit s√ªr (vous en aurez besoin pour la configuration)

### 1.3 (Optionnel) Pr√©parer GitHub

Si vous d√©ployez depuis GitHub :

1. **Cr√©er un d√©p√¥t** (ou utiliser existant) : https://github.com/new
2. **Cloner localement** (si pas d√©j√† fait)
3. **Copier les fichiers** :
   ```bash
   cp Backend/Dockerfile.runpod /chemin/vers/repo/
   cp Backend/app_runpod.py /chemin/vers/repo/
   cp Backend/requirements.runpod.txt /chemin/vers/repo/
   ```
4. **Commit et push** :
   ```bash
   git add Dockerfile.runpod app_runpod.py requirements.runpod.txt
   git commit -m "Add Vast.ai deployment files"
   git push origin main
   ```

---

## üîê √âtape 2 : Cr√©ation Compte Vast.ai

### 2.1 Cr√©er le Compte

**Lien :** https://vast.ai/

**√âtapes :**
1. Aller sur https://vast.ai/
2. Cliquer sur **"Sign Up"** (en haut √† droite)
3. Remplir :
   - **Email** : votre email
   - **Password** : mot de passe s√©curis√©
   - **Confirm Password** : confirmation
4. Accepter les conditions
5. Cliquer sur **"Sign Up"**
6. V√©rifier l'email (lien de confirmation)
7. Se connecter : https://vast.ai/ (cliquer sur **"Sign In"**)

### 2.2 V√©rifier le Compte

**Dashboard :** https://vast.ai/console/instances

**V√©rifications :**
- ‚úÖ Compte cr√©√© et v√©rifi√©
- ‚úÖ Email confirm√©
- ‚úÖ Peut acc√©der au dashboard

**Note :** Pas de d√©p√¥t minimum g√©n√©ralement requis ‚úÖ

---

## ‚öôÔ∏è √âtape 3 : Configuration Instance

### 3.1 Acc√©der √† la Cr√©ation d'Instance

**Lien direct :** https://vast.ai/console/create

**Ou depuis le dashboard :**
1. Aller sur https://vast.ai/console/instances
2. Cliquer sur **"Create"** (bouton vert en haut)

### 3.2 Choisir le Type d'Instance

**‚ö†Ô∏è Important :** Vast.ai propose plusieurs types d'instances. Pour Spinoza Secours, nous avons besoin d'une **instance Docker**, pas d'une VM.

**Options que vous pouvez voir :**

| Option | Type | Pour Spinoza Secours |
|--------|------|----------------------|
| **Ubuntu 22.04 VM** | Machine virtuelle compl√®te | ‚ùå **NE PAS CHOISIR** |
| **Ubuntu Desktop (VM)** | VM avec interface graphique | ‚ùå **NE PAS CHOISIR** |
| **SSH** | Acc√®s SSH direct | ‚ùå **NE PAS CHOISIR** |
| **Docker** / **Container** | Container Docker | ‚úÖ **√Ä CHOISIR** |
| **Custom Dockerfile** | Dockerfile personnalis√© | ‚úÖ **√Ä CHOISIR** |

**‚ö†Ô∏è Si vous voyez "Ubuntu 22.04 VM" ou "Ubuntu Desktop (VM)" :**
- Ces options sont des **machines virtuelles compl√®tes**
- Elles ne sont **pas adapt√©es** pour notre cas (FastAPI avec Dockerfile)
- **Ne pas les s√©lectionner**

**‚úÖ Ce qu'il faut chercher :**
1. **Option "Docker"** ou **"Container"**
2. **Option "Custom Dockerfile"** ou **"Dockerfile"**
3. **Option "From GitHub"** (qui permet de sp√©cifier un Dockerfile)

**Si vous ne trouvez pas ces options :**
- Regarder dans les **onglets** ou **options avanc√©es**
- Chercher un champ **"Source"** ou **"Repository"** o√π vous pouvez entrer un Dockerfile
- V√©rifier s'il y a un onglet **"Docker"** ou **"Container"**
- Consulter la documentation Vast.ai : https://docs.vast.ai/

**Note :** L'interface Vast.ai peut varier selon les versions. L'important est de trouver une option qui permet d'utiliser un **Dockerfile** (comme `Backend/Dockerfile.runpod`), pas une VM compl√®te.

### 3.3 S√©lectionner le GPU

**Section :** "Choose GPU"

**Recommandation :** **RTX 4090** ‚≠ê‚≠ê (ou **RTX 3090** ‚≠ê si indisponible ou budget serr√©)

**Pourquoi RTX 4090 (RECOMMAND√â) :**
- **Co√ªt : $0.29/h** ‚úÖ (tarif v√©rifi√© Janvier 2025)
- Performance : 3-4x plus rapide que T4
- VRAM : 24GB (suffisant pour Mistral 7B en 4-bit)
- **Meilleur rapport performance/prix** : Plus rapide que RTX 3090 pour prix similaire

**Pourquoi RTX 3090 (EXCELLENTE ALTERNATIVE) :**
- **Co√ªt : $0.20-0.40/h** (peut √™tre moins cher que RTX 4090 selon offre)
- **Performance : 2-3x plus rapide que T4** (largement suffisant)
- **VRAM : 24GB** (identique √† RTX 4090, suffisant pour Mistral 7B)
- **Disponibilit√© :** G√©n√©ralement disponible
- **Rapport qualit√©/prix :** Excellent si trouv√© √† $0.20-0.25/h
- **√âconomie :** Jusqu'√† 31% moins cher que RTX 4090 si √† $0.20/h

**S√©lection :**
1. **Option A (Performance) :** Chercher **"RTX 4090"** √† **$0.29/h** ‚≠ê‚≠ê
2. **Option B (Budget) :** Chercher **"RTX 3090"** √† **$0.20-0.25/h** ‚≠ê (excellent rapport qualit√©/prix)
3. Filtrer par :
   - **VRAM** : 24GB (minimum)
   - **Prix** : 
     - RTX 4090 : $0.29/h (optimal)
     - RTX 3090 : $0.20-0.25/h (recommand√©) ou $0.26-0.40/h (acceptable)
4. **Recommandation :** Si RTX 3090 < $0.25/h ‚Üí choisir RTX 3090 (√©conomies 14-31%)
5. S√©lectionner une offre disponible

**Autres options :**
- **RTX 3060 12GB** : $0.15-0.25/h (moins cher mais moins performant, VRAM limite)

### 3.4 Configurer l'Instance

**Interface Vast.ai :** Lors de la cr√©ation d'instance, vous verrez plusieurs sections :

#### Template (S√©lection ou Cr√©ation)

**Qu'est-ce qu'un Template ?**
- Configuration r√©utilisable pour cr√©er plusieurs instances identiques
- Vast.ai propose 38+ templates pr√©-configur√©s
- Vous pouvez aussi cr√©er votre propre template personnalis√©

**‚ö†Ô∏è Important :** Aucun template pr√©-configur√© ne correspond exactement √† Spinoza Secours. Il faut utiliser un **Dockerfile personnalis√©**.

**Options disponibles :**

**Option A : Utiliser un Template de Base (Recommand√© pour d√©buter)**

Parmi les templates disponibles, les plus proches sont :
- **"NVIDIA CUDA"** : Base image avec CUDA (peut servir de point de d√©part)
- **"PyTorch (Vast)"** : PyTorch pr√©-install√© (peut servir de point de d√©part)

**‚ö†Ô∏è Mais attention :** Ces templates ne contiennent pas notre application. Il faut quand m√™me configurer un **Dockerfile personnalis√©** pour utiliser `Backend/Dockerfile.runpod`.

**Option B : Cr√©er un Template Personnalis√© (Recommand√© pour r√©utilisation)**

1. Lors de la cr√©ation d'instance, **ne pas s√©lectionner de template pr√©-configur√©**
2. Configurer manuellement :
   - Dockerfile : Utiliser `Backend/Dockerfile.runpod` (voir section Configuration Docker)
   - Variables d'environnement : `HF_TOKEN`, `PORT`
   - Storage : 50GB minimum
   - Port : 8000
3. Apr√®s configuration, chercher **"Save as Template"** ou **"Create Template"**
4. **Nom** : `spinoza-secours-mistral7b`
5. **Description** : "Spinoza Secours API - Mistral 7B + LoRA"
6. Sauvegarder

**Utiliser un Template Personnalis√© :**
1. Lors de la cr√©ation d'instance, s√©lectionner **"From Template"** ou chercher dans vos templates
2. Choisir le template `spinoza-secours-mistral7b`
3. Les configurations sont pr√©-remplies ‚úÖ
4. Ajuster si n√©cessaire (GPU, variables d'environnement)

**Option C : Pas de Template (Configuration Manuelle √† Chaque Fois)**

1. **Ne pas s√©lectionner de template** dans la liste
2. Configurer manuellement toutes les options (voir sections suivantes)
3. Plus long mais plus flexible

---

#### Configuration Docker

**‚ö†Ô∏è Important :** Il n'y a **pas de section "Docker Image"** d√©di√©e sur l'interface Vast.ai. La configuration Docker se fait dans les sections **Template**, **Instances** ou dans les param√®tres de configuration.

**O√π configurer Docker :**

1. **Si vous avez s√©lectionn√© un template** : Chercher une option **"Custom Dockerfile"**, **"Dockerfile"** ou **"Override Image"** dans les param√®tres du template
2. **Si vous cr√©ez une instance manuelle** : Chercher un champ **"Dockerfile"**, **"Custom Dockerfile"** ou **"Source"** dans les param√®tres d'instance
3. **Dans les options avanc√©es** : Regarder dans les onglets ou param√®tres avanc√©s

**O√π trouver la configuration Docker :**

1. **Dans la section Template** (si vous cr√©ez/s√©lectionnez un template)
2. **Dans les param√®tres d'instance** (champs de configuration)
3. **Dans les options avanc√©es** (selon la version de l'interface)

**Option A : Depuis GitHub (Recommand√©)**

1. Chercher un champ **"Source"**, **"Repository"**, **"GitHub"** ou **"From GitHub"** dans les sections Template/Instances
2. Entrer le repository : `FJDaz/Spinoza_secours` (ou votre repo)
3. **Branch** : `main` (ou la branche appropri√©e)
4. **Dockerfile Path** : `Backend/Dockerfile.runpod`
5. **Dockerfile Context** : `/` (racine du repo) - si champ disponible

**Option B : Dockerfile Direct**

1. Chercher un champ **"Dockerfile"**, **"Custom Dockerfile"** ou zone de texte pour Dockerfile
2. Copier le contenu de `Backend/Dockerfile.runpod`
3. Coller dans le champ

**Option C : Image Docker Hub (Si publi√©e)**

1. Chercher un champ **"Image"** ou **"Docker Hub"**
2. Entrer : `votre-username/spinoza-secours:latest`

**Si vous ne trouvez pas ces champs :**
- Regarder dans les **options avanc√©es** ou **param√®tres avanc√©s**
- V√©rifier s'il y a un onglet **"Docker"** ou **"Container"**
- Consulter la documentation Vast.ai : https://docs.vast.ai/
- Les champs peuvent √™tre dans la section **Template** ou **Instances**

---

#### Instances (Configuration Instance)

**Section :** "Instance Settings" ou "Configuration"

**Param√®tres √† v√©rifier :**
- **Instance Name** : `spinoza-secours-001` (optionnel, pour identification)
- **Auto-start** : D√©sactiv√© par d√©faut (d√©marrage manuel recommand√©)
- **Auto-stop** : Optionnel (voir section Auto-Sleep)
- **Restart Policy** : `on-failure` (red√©marrage si crash)

**Recommandations :**
- **Instance Name** : Utiliser un nom descriptif pour faciliter l'identification
- **Auto-start** : Laisser d√©sactiv√© pour contr√¥ler les co√ªts
- **Restart Policy** : `on-failure` pour √©viter les red√©marrages inutiles

---

#### Storage (Stockage)

**Section :** "Storage" ou "Disk" (d√©j√† d√©taill√©e en section 3.5, rappel ici)

**Container Disk (Gratuit) :**
- **Taille** : **50GB minimum**
- **Type** : Stockage √©ph√©m√®re (effac√© √† l'arr√™t)
- **Co√ªt** : Inclus dans le prix GPU
- **Avantage** : Gratuit
- **Inconv√©nient** : Mod√®le ret√©l√©charg√© √† chaque d√©marrage (10-15 min)

**Volume Disk (Persistant) :**
- **Taille** : 50GB minimum (recommand√© : 100GB pour marge)
- **Type** : Stockage persistant (conserv√© entre red√©marrages)
- **Co√ªt** : +$0.10-0.20/h suppl√©mentaire
- **Avantage** : Mod√®le conserv√©, d√©marrage rapide (6-12 min vs 16-27 min)
- **Rentabilit√©** : Si usage > 4h/jour avec red√©marrages fr√©quents

**Configuration Storage :**
1. **Container Disk** : S√©lectionner **50GB** (ou plus)
2. **Volume Disk** (optionnel) : Cocher si besoin de persistance
   - S√©lectionner taille : 50-100GB
   - V√©rifier le co√ªt suppl√©mentaire affich√©
3. **Mount Point** : `/workspace` ou `/data` (par d√©faut)

**‚ö†Ô∏è Important :**
- **Container Disk** : Suffisant pour usage ponctuel
- **Volume Disk** : Recommand√© pour usage fr√©quent (voir section Cold Start)

### 3.5 Configurer les Variables d'Environnement

**Section :** "Environment Variables" ou "Env"

**Ajouter :**

| Variable | Valeur | Description |
|----------|--------|-------------|
| `HF_TOKEN` | `votre_token_hf` | Token Hugging Face (obtenu √† l'√©tape Pr√©requis #2) |
| `PORT` | `8000` | Port FastAPI |

**Format :**
```
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
PORT=8000
```

**‚ö†Ô∏è Important :** Remplacer `votre_token_hf` par le vrai token Hugging Face

### 3.6 Configurer le Stockage

**Section :** "Storage" ou "Disk"

**Container Disk :** **50GB minimum**

**Pourquoi :**
- Mod√®le Mistral 7B : ~14GB
- LoRA adapter : ~100MB
- Syst√®me + d√©pendances : ~5GB
- Marge : ~30GB

**Configuration :**
- **Container Disk** : 50GB (ou plus si disponible)
  - **Type :** Stockage √©ph√©m√®re (perdu √† l'arr√™t de l'instance)
  - **Co√ªt :** Inclus dans le prix de l'instance
  - **Inconv√©nient :** Mod√®le ret√©l√©charg√© √† chaque d√©marrage (~10-15 min)

**Option : Volume Disk Persistant**
- **Type :** Stockage persistant (conserv√© entre red√©marrages)
- **Co√ªt :** +$0.10-0.20/h suppl√©mentaire
- **Avantage :** Mod√®le conserv√©, d√©marrage rapide (~2-3 min)
- **Rentabilit√© :** Voir calcul ci-dessous

**Calcul Rentabilit√© Volume Disk :**
- **Seuil :** Si instance utilis√©e > 4h/jour avec red√©marrages fr√©quents
- **Gain temps :** 10-15 min √©conomis√©es par red√©marrage
- **Exemple :** Usage 8h/jour avec 2 red√©marrages = 20-30 min √©conomis√©es
  - Volume Disk : $0.80-1.60/jour
  - Si valeur temps > co√ªt ‚Üí Volume Disk rentable

### 3.7 Configurer le Port

**Section :** "Ports" ou "Network"

**Port :** **8000**

**Configuration :**
- **Internal Port** : 8000
- **External Port** : Vast.ai mappe automatiquement (g√©n√©ralement m√™me port 8000)
- **Protocol** : HTTP (ou TCP)

**‚ö†Ô∏è Important :** 
- Vast.ai mappe automatiquement les ports
- L'URL publique sera de type `http://votre-instance.vast.ai:8000`
- **V√©rification :** Apr√®s cr√©ation de l'instance, aller dans Dashboard ‚Üí Instance ‚Üí Connect/Public URL pour r√©cup√©rer l'URL exacte
- Le port externe est g√©n√©ralement le m√™me que le port interne (8000), mais peut varier selon la configuration Vast.ai


### 3.8 R√©viser la Configuration

**V√©rifications avant cr√©ation :**

- [ ] GPU : RTX 3090 s√©lectionn√©
- [ ] Docker : Dockerfile configur√© (GitHub ou direct)
- [ ] Variables d'environnement : `HF_TOKEN` et `PORT` d√©finis
- [ ] Container Disk : 50GB minimum
- [ ] Port : 8000 expos√©

**Co√ªt estim√© :** 
- **RTX 4090 : $0.29/h** ‚úÖ (recommand√©)
- RTX 3090 : $0.20-0.40/h (alternative)

---

## üöÄ √âtape 4 : D√©ploiement

### 4.1 Lancer l'Instance

**Action :** Cliquer sur **"Create"** ou **"Deploy"**

**Lien dashboard :** https://vast.ai/console/instances

**√âtapes :**
1. V√©rifier toutes les configurations (√©tape 3)
2. Cliquer sur **"Create Instance"** ou **"Deploy"**
3. Attendre la confirmation

### 4.2 Suivre le Build Docker

**Temps estim√© :** 5-10 minutes

**O√π voir les logs :**
- Dashboard ‚Üí Votre instance ‚Üí **"Logs"** ou **"Console"**

**Ce qui se passe :**
1. Build de l'image Docker
2. Installation des d√©pendances Python
3. T√©l√©chargement des packages (torch, transformers, etc.)

**Logs attendus :**
```
Building Docker image...
Installing dependencies...
Collecting torch>=2.0.0
Collecting transformers>=4.35.0
...
Successfully built image
```

### 4.3 Attendre le Chargement du Mod√®le (Cold Start)

**Temps estim√© :** 
- **Container Disk** : 10-15 minutes (t√©l√©chargement mod√®le)
- **Volume Disk** : 1-2 minutes (mod√®le d√©j√† pr√©sent)

**Voir section d√©taill√©e :** [Cold Start](#-cold-start-d√©marrage-√†-froid)

**O√π voir les logs :**
- Dashboard ‚Üí Votre instance ‚Üí **"Logs"**

**Ce qui se passe :**
1. T√©l√©chargement Mistral 7B depuis Hugging Face (~14GB)
2. T√©l√©chargement LoRA adapter (~100MB)
3. Chargement du mod√®le en m√©moire GPU
4. Application de la quantization 4-bit

**Logs attendus :**
```
üñ•Ô∏è GPU disponible: True
üîÑ Chargement Mistral 7B (4-bit GPU)...
Downloading model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.2G/14.2G
üîÑ Application LoRA Spinoza_Secours...
‚úÖ Mod√®le Mistral 7B + LoRA charg√©!
üöÄ D√©marrage du serveur FastAPI sur le port 8000...
```

**‚ö†Ô∏è Important :** Ne pas arr√™ter l'instance pendant le t√©l√©chargement

### 4.4 V√©rifier le D√©marrage du Serveur

**Logs attendus :**
```
üöÄ D√©marrage du serveur FastAPI sur le port 8000...
üì° Endpoints disponibles:
   - GET  /health
   - GET  /init
   - POST /chat
   - POST /evaluate
INFO:     Started server process
INFO:     Uvicorn running on http://0.0.0.0:8000
```

**Si vous voyez ces logs :** ‚úÖ Le serveur est d√©marr√© et pr√™t

### 4.5 R√©cup√©rer l'URL Publique

**O√π trouver :**
- Dashboard ‚Üí Votre instance ‚Üí **"Connect"** ou **"Public URL"**

**Format d'URL :**
- `http://votre-instance.vast.ai:8000`
- ou `https://votre-instance.vast.ai:8000` (si HTTPS activ√©)

**Exemple :**
```
http://abc123def456.vast.ai:8000
```

**‚ö†Ô∏è Important :** Noter cette URL, vous en aurez besoin pour le frontend

---

## üß™ √âtape 5 : Tests

### 5.1 Test Health Check

**Commande :**
```bash
curl http://votre-instance.vast.ai:8000/health
```

**R√©ponse attendue :**
```json
{
  "status": "ok",
  "model": "Mistral 7B + LoRA",
  "gpu_available": true
}
```

**Si `gpu_available: false` :** ‚ö†Ô∏è Probl√®me de configuration GPU

### 5.2 Test Initialisation

**Commande :**
```bash
curl http://votre-instance.vast.ai:8000/init
```

**R√©ponse attendue :**
```json
{
  "greeting": "Bonjour ! Je suis Spinoza. Discutons :\n\n**La libert√© est-elle une illusion ?**\n\nQu'en penses-tu ?",
  "history": [[null, "Bonjour ! Je suis Spinoza..."]]
}
```

### 5.3 Test Chat

**Commande :**
```bash
curl -X POST http://votre-instance.vast.ai:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Bonjour Spinoza, qu'\''est-ce que le conatus ?",
    "history": []
  }'
```

**R√©ponse attendue :**
```json
{
  "reply": "Le conatus est l'\''effort que chaque chose fait pour pers√©v√©rer dans son √™tre...",
  "history": [["Bonjour Spinoza...", "Le conatus est..."]]
}
```

**Temps de r√©ponse :** 2-5 secondes (RTX 3090)

### 5.4 Test √âvaluation (Ma√Øathon)

**Commande :**
```bash
curl -X POST http://votre-instance.vast.ai:8000/evaluate \
  -H "Content-Type: application/json" \
  -d '{
    "dialogue": "Spinoza: Bonjour ! Je suis Spinoza. Discutons : La libert√© est-elle une illusion ?\n√âl√®ve: Je pense que oui, tout est d√©termin√©.\nSpinoza: Tu dis que tout est d√©termin√©... qu'\''est-ce que √ßa veut dire pour toi ?",
    "score_front": 55
  }'
```

**R√©ponse attendue :**
```json
{
  "score_final": 85,
  "message_final": "Ton effort pour comprendre tes propres affects est impressionnant...",
  "details_model": {
    "comprehension": 8,
    "cooperation": 9,
    "progression": 8,
    "total": 25
  }
}
```

**Temps de r√©ponse :** 5-10 secondes (RTX 3090)

### 5.5 Test Automatique (Script)

**Script :** `Backend/test_runpod_deployment.sh`

**Commande :**
```bash
cd /Users/francois-jeandazin/bergsonAndFriends/Spinoza_Secours_HF/Backend/
chmod +x test_runpod_deployment.sh
./test_runpod_deployment.sh http://votre-instance.vast.ai:8000
```

**R√©sultat attendu :** Tous les tests passent ‚úÖ

---

## üé® √âtape 6 : Mise √† Jour Frontend

### 6.1 Localiser le Fichier

**Fichier :** `Frontend/index_spinoza.html`

**Chemin complet :** `/Users/francois-jeandazin/bergsonAndFriends/Spinoza_Secours_HF/Frontend/index_spinoza.html`

### 6.2 Modifier l'URL Backend

**Ligne √† modifier :** Ligne 127 (v√©rifi√©e)

**Ancien code :**
```javascript
const API_BASE_URL = 'https://nonremunerative-rory-unbreakably.ngrok-free.dev';
```

**Nouveau code :**
```javascript
const API_BASE_URL = 'http://votre-instance.vast.ai:8000';
```

**‚ö†Ô∏è Important :** Remplacer `votre-instance.vast.ai:8000` par votre vraie URL Vast.ai

### 6.3 V√©rifier la Modification

**V√©rification :**
1. Ouvrir `Frontend/index_spinoza.html`
2. Chercher `API_BASE_URL` (ligne ~120)
3. V√©rifier que l'URL correspond √† votre instance Vast.ai

### 6.4 Tester Localement

**√âtapes :**
1. Ouvrir `Frontend/index_spinoza.html` dans un navigateur
2. Ouvrir la console d√©veloppeur (F12)
3. V√©rifier qu'il n'y a pas d'erreurs CORS
4. Cliquer sur "Commencer"
5. V√©rifier que la question initiale de Spinoza s'affiche
6. Envoyer une r√©ponse
7. V√©rifier que Spinoza r√©pond

**Si erreur CORS :** V√©rifier que le backend autorise votre origine (voir Troubleshooting)

### 6.5 Mettre √† Jour sur le Serveur

**Si le frontend est h√©berg√© sur fjdaz.com :**

**M√©thode 1 : FTP/SFTP**
1. Se connecter au serveur
2. Uploader `index_spinoza.html` mis √† jour
3. Remplacer l'ancien fichier

**M√©thode 2 : Git**
1. Committer les changements :
   ```bash
   git add Frontend/index_spinoza.html
   git commit -m "Update backend URL to Vast.ai"
   git push origin main
   ```
2. Si d√©ploiement automatique, attendre le d√©ploiement

**M√©thode 3 : Interface d'h√©bergement**
1. Utiliser l'interface de votre h√©bergeur
2. Uploader le fichier mis √† jour

---

## ‚úÖ √âtape 7 : Validation Compl√®te

### 7.1 Test Complet Frontend + Backend

**√âtapes :**
1. Ouvrir `Frontend/index_spinoza.html` (local ou sur serveur)
2. Cliquer sur "Commencer"
3. V√©rifier que la question initiale s'affiche
4. Compl√©ter les 5 √©changes avec Spinoza
5. V√©rifier que le score s'affiche en temps r√©el
6. V√©rifier que l'√©valuation finale fonctionne
7. V√©rifier que le message final de Spinoza s'affiche
8. V√©rifier que le titre "Ma√Øathon" et "R√©fl√©chis. Reformule. Questionne." s'affichent

### 7.2 V√©rifier les Performances

**Latences attendues :**

| GPU | Inf√©rence dialogue | √âvaluation finale | Latence totale |
|-----|-------------------|-------------------|----------------|
| **T4 (Colab)** | 2-5s | 5-10s | 8-16s |
| **RTX 3090** | 1-3s | 3-6s | 4-9s |
| **RTX 4090** | **0.7-1.5s** | **2-4s** | **2.7-5.5s** |

**Gain RTX 4090 vs RTX 3090 :** ~1.3-3.5 secondes par requ√™te compl√®te

**Si latence trop √©lev√©e :** V√©rifier que le GPU est bien utilis√© (`gpu_available: true`)

### 7.3 V√©rifier la Stabilit√©

**Tests de stabilit√© :**
1. Faire plusieurs dialogues complets
2. V√©rifier que l'instance ne crash pas
3. V√©rifier que les r√©ponses sont coh√©rentes
4. V√©rifier que le score fonctionne correctement

### 7.4 Documenter l'URL

**Action :** Noter l'URL Vast.ai dans un endroit s√ªr

**Format :**
```
URL Backend Vast.ai : http://votre-instance.vast.ai:8000
Date de d√©ploiement : [date]
GPU : RTX 3090
Co√ªt : $0.20-0.40/h
```

---

## üîí S√©curit√© et Bonnes Pratiques

### ‚ö†Ô∏è Points Critiques de S√©curit√©

#### 1. Configuration CORS (CRITIQUE)

**Probl√®me actuel :** Le code autorise toutes les origines (`allow_origins=["*"]`)

**Fichier :** `Backend/app_runpod.py` ligne 543

**Action REQUISE avant production :**

```python
# ‚ùå ACTUEL (INS√âCURIS√â)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ‚ö†Ô∏è DANGEREUX
    ...
)

# ‚úÖ CORRIGER EN (PRODUCTION)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://fjdaz.com",
        "https://www.fjdaz.com",
        # "http://localhost:8000",  # ‚ö†Ô∏è RETIRER en production, garder seulement pour dev local
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["Content-Type"],
)

# Pour d√©veloppement local, utiliser une configuration s√©par√©e :
# allow_origins=["http://localhost:8000", "http://127.0.0.1:8000"]  # Dev uniquement
```

**√âtapes :**
1. Modifier `Backend/app_runpod.py` ligne 543
2. Remplacer `allow_origins=["*"]` par la liste de vos domaines
3. Commit et push sur GitHub
4. Red√©marrer l'instance Vast.ai

**V√©rification :**
```bash
# Tester depuis un domaine non autoris√© (doit √©chouer)
curl -H "Origin: https://evil.com" http://votre-instance.vast.ai:8000/health
```

#### 2. Gestion des Tokens (CRITIQUE)

**R√®gles de s√©curit√© :**

‚úÖ **√Ä FAIRE :**
- Token Hugging Face stock√© uniquement dans variables d'environnement Vast.ai
- Token avec permissions minimales (Read uniquement)
- Token r√©g√©n√©r√© tous les 90 jours minimum
- Token jamais commit√© dans Git
- Token jamais affich√© dans les logs

‚ùå **√Ä NE JAMAIS FAIRE :**
- Hardcoder le token dans le code
- Commit le token dans Git
- Partager le token par email/chat non chiffr√©
- Utiliser le m√™me token pour plusieurs projets
- Token avec permissions Write si non n√©cessaire

**V√©rification :**
```bash
# V√©rifier qu'aucun token n'est dans le code (version am√©lior√©e)
grep -r "hf_\|HUGGINGFACE_TOKEN\|HF_TOKEN" \
  Backend/ \
  --exclude-dir=.git \
  --exclude-dir=venv \
  --exclude-dir=__pycache__ \
  --exclude-dir=.venv \
  --exclude="*.pyc"
# R√©sultat attendu : Aucun r√©sultat (ou seulement les commentaires/documentation)
```

#### 3. Rate Limiting (RECOMMAND√â)

**Probl√®me :** Aucune protection contre l'abus (spam, DoS)

**Solution :** Ajouter rate limiting sur les endpoints

**Fichier √† modifier :** `Backend/app_runpod.py`

**Ajout apr√®s les imports :**
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)
```

**Ajout sur les endpoints :**
```python
@app.post("/chat")
@limiter.limit("10/minute")  # 10 requ√™tes par minute par IP
def chat(req: ChatRequest):
    ...

@app.post("/evaluate")
@limiter.limit("5/minute")  # 5 requ√™tes par minute par IP
def evaluate(req: EvaluateRequest):
    ...
```

**D√©pendance √† ajouter :** `slowapi>=0.1.9` dans `requirements.runpod.txt`

**‚ö†Ô∏è Important :** Apr√®s ajout de `slowapi`, red√©ployer compl√®tement l'instance (rebuild Docker requis)

#### 4. Validation des Inputs (CRITIQUE)

**V√©rification actuelle :** Pydantic valide les types mais pas le contenu

**Am√©liorations n√©cessaires :**

```python
from pydantic import BaseModel, field_validator
import html

class ChatRequest(BaseModel):
    message: str
    history: Optional[List[List[str]]] = None
    
    @field_validator('message')  # Pydantic v2 (requirements.runpod.txt sp√©cifie >=2.5.0)
    @classmethod
    def validate_message(cls, v: str) -> str:
        # Limiter la longueur
        if len(v) > 2000:
            raise ValueError('Message trop long (max 2000 caract√®res)')
        
        # Rejeter les tentatives d'injection XSS
        xss_patterns = ['<script', 'javascript:', 'onerror=', 'onload=', '<iframe']
        if any(pattern in v.lower() for pattern in xss_patterns):
            raise ValueError('Contenu non autoris√©')
        
        # √âchapper les entit√©s HTML
        v = html.escape(v)
        
        return v
```

#### 5. HTTPS (RECOMMAND√â)

**Probl√®me :** Vast.ai peut exposer en HTTP par d√©faut

**Solutions :**

**Option A : Cloudflare Tunnel (RECOMMAND√â - Gratuit)**

**√âtapes d√©taill√©es :**

1. **Cr√©er compte Cloudflare** : https://dash.cloudflare.com/sign-up
2. **Installer cloudflared** sur votre machine locale :
   ```bash
   # macOS
   brew install cloudflare/cloudflare/cloudflared
   
   # Linux
   wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64
   chmod +x cloudflared-linux-amd64
   sudo mv cloudflared-linux-amd64 /usr/local/bin/cloudflared
   ```
3. **Authentifier** :
   ```bash
   cloudflared tunnel login
   ```
4. **Cr√©er un tunnel** :
   ```bash
   cloudflared tunnel create spinoza-secours
   ```
5. **Configurer le tunnel** (cr√©er `config.yml`) :
   ```yaml
   tunnel: [tunnel-id]
   credentials-file: /path/to/credentials.json
   
   ingress:
     - hostname: spinoza-secours.votre-domaine.com
       service: http://votre-instance.vast.ai:8000
     - service: http_status:404
   ```
6. **D√©marrer le tunnel** :
   ```bash
   cloudflared tunnel run spinoza-secours
   ```
7. **Configurer DNS** dans Cloudflare :
   - Type : CNAME
   - Nom : spinoza-secours (ou @ pour racine)
   - Cible : [tunnel-id].cfargotunnel.com
8. **URL finale** : `https://spinoza-secours.votre-domaine.com`

**Avantages :** Gratuit, HTTPS automatique, pas d'exposition directe de l'IP Vast.ai

**Option B : Vast.ai avec HTTPS natif**

**V√©rifier dans le dashboard Vast.ai** si HTTPS est disponible :
- Dashboard ‚Üí Instance ‚Üí Network ‚Üí HTTPS
- Si disponible, suivre les instructions Vast.ai

**Option C : ngrok avec HTTPS (Alternative)**

**√âtapes :**
1. Cr√©er compte ngrok : https://dashboard.ngrok.com/signup
2. Installer ngrok
3. Authentifier : `ngrok config add-authtoken [token]`
4. Cr√©er tunnel : `ngrok http http://votre-instance.vast.ai:8000`
5. URL HTTPS fournie automatiquement

**Inconv√©nient :** URL change √† chaque d√©marrage (comme Colab)

**V√©rification :**
```bash
# Tester que HTTPS fonctionne
curl https://votre-url-cloudflare.com/health
# ou
curl https://votre-instance.vast.ai:8000/health  # Si HTTPS natif
```

#### 6. Monitoring des Co√ªts (CRITIQUE)

**Risque :** Facture explosive si instance laiss√©e tourner

**Solutions :**

1. **Alertes Vast.ai** (si disponible dans le dashboard)
   - Dashboard ‚Üí Settings ‚Üí Alerts
   - Configurer une alerte √† $X d√©pens√©s
   - Configurer une alerte si instance tourne > X heures
   - **Note :** V√©rifier si cette fonctionnalit√© existe dans votre compte

2. **Monitoring manuel quotidien**
   - V√©rifier le dashboard Vast.ai : https://vast.ai/console/instances
   - Noter les co√ªts dans un fichier (ex: `docs/logs/couts_vast_ai.md`)
   - **Fr√©quence recommand√©e :** Quotidien si instance active

3. **Script de monitoring des co√ªts** (voir section Maintenance ‚Üí Monitoring)

4. **Bonnes pratiques :**
   - **Toujours arr√™ter l'instance** apr√®s usage
   - **Ne pas laisser tourner** en veille "au cas o√π"
   - **Configurer un rappel** (calendrier, alarme) pour v√©rifier l'instance
   - **Noter dans un calendrier** les dates de d√©marrage/arr√™t

**Dashboard Vast.ai :** https://vast.ai/console/instances

#### 7. Protection Prompt Injection (SP√âCIFIQUE LLM)

**Risque :** Utilisateur peut injecter des prompts malveillants

**Protection actuelle :** Partielle (validation basique)

**Am√©liorations :**

```python
def sanitize_user_input(text: str) -> str:
    """Nettoie l'input utilisateur pour √©viter prompt injection"""
    # Supprimer les tentatives de formatage sp√©cial
    text = text.replace('[INST]', '').replace('[/INST]', '')
    text = text.replace('<s>', '').replace('</s>', '')
    # Limiter la longueur
    return text[:2000]

# Utiliser dans les endpoints
@app.post("/chat")
def chat(req: ChatRequest):
    sanitized_message = sanitize_user_input(req.message)
    ...
```

#### 8. Logs et Donn√©es Sensibles

**R√®gles :**

‚úÖ **√Ä FAIRE :**
- Ne pas logger les tokens/secrets
- Anonymiser les donn√©es utilisateur dans les logs
- Limiter les logs en production (INFO uniquement)

‚ùå **√Ä NE JAMAIS FAIRE :**
- Logger les tokens Hugging Face
- Logger les messages utilisateurs complets
- Exposer les logs publiquement

**V√©rification :**
```bash
# V√©rifier les logs ne contiennent pas de tokens
grep -i "hf_\|token\|secret" logs/*.log
# R√©sultat attendu : Aucun r√©sultat
```

### Checklist S√©curit√© Avant Production

- [ ] CORS restreint aux domaines autoris√©s uniquement
- [ ] Token Hugging Face en variable d'environnement (pas hardcod√©)
- [ ] Rate limiting activ√© sur endpoints critiques
- [ ] Validation stricte des inputs utilisateur
- [ ] HTTPS configur√© (ou reverse proxy avec HTTPS)
- [ ] Monitoring des co√ªts configur√©
- [ ] Protection prompt injection impl√©ment√©e
- [ ] Logs ne contiennent pas de donn√©es sensibles
- [ ] `.env` dans `.gitignore` (si utilis√©)
- [ ] Scan s√©curit√© effectu√© (`grep -r "hf_\|password\|secret"` = vide)

---

## üîß Maintenance et Monitoring

### 1. Monitoring de Base

#### M√©triques √† Surveiller

**Disponibilit√© :**
- Uptime de l'instance Vast.ai
- Temps de r√©ponse des endpoints
- Taux d'erreur (5xx)

**Performance :**
- Latence moyenne des requ√™tes
- Utilisation GPU (VRAM, compute)
- Temps de g√©n√©ration du mod√®le

**Co√ªts :**
- Co√ªt par heure
- Co√ªt total depuis d√©marrage
- Estimation co√ªt mensuel si 24/7

**O√π surveiller :**
- **Dashboard Vast.ai :** https://vast.ai/console/instances
- **Logs instance :** Dashboard ‚Üí Instance ‚Üí Logs
- **Health check :** `curl http://votre-instance.vast.ai:8000/health`

#### Health Check Automatis√©

**Script de monitoring (√† cr√©er) :**

```bash
#!/bin/bash
# monitor_vast_ai.sh
# Usage: Ajouter dans cron pour v√©rifier toutes les heures

INSTANCE_URL="http://votre-instance.vast.ai:8000"
ALERT_EMAIL="votre-email@example.com"

# Test health check
response=$(curl -s -o /dev/null -w "%{http_code}" "$INSTANCE_URL/health")

if [ "$response" != "200" ]; then
    echo "ALERT: Instance Vast.ai down (HTTP $response)" | mail -s "Vast.ai Alert" "$ALERT_EMAIL"
fi
```

**Cron :**
```bash
# V√©rifier toutes les heures
0 * * * * /chemin/vers/monitor_vast_ai.sh
```

### 2. Logs et Debugging

#### Configuration des Logs

**Niveaux de log :**
- **Production :** INFO (pas de DEBUG)
- **D√©veloppement :** DEBUG

**Fichier :** `Backend/app_runpod.py` lignes 619-624

```python
uvicorn.run(
    app,
    host="0.0.0.0",
    port=PORT,
    log_level="info"  # "info" en prod, "debug" en dev
)
```

#### Rotation des Logs

**Si logs volumineux :**
- Configurer logrotate ou √©quivalent
- Conserver 7 jours de logs maximum
- Archivage au-del√†

#### Acc√®s aux Logs Vast.ai

**Dashboard :** https://vast.ai/console/instances ‚Üí Votre instance ‚Üí **Logs**

**Commandes utiles :**
```bash
# Voir les derni√®res erreurs
# (via dashboard Vast.ai ou SSH si disponible)

# Filtrer les erreurs
grep -i "error\|exception\|traceback" logs.txt

# Voir les requ√™tes
grep "POST /chat" logs.txt
```

### 3. Backups et R√©cup√©ration

#### Configuration √† Sauvegarder

**Fichiers critiques :**
- `Backend/app_runpod.py` (code principal)
- `Backend/Dockerfile.runpod` (configuration Docker)
- `Backend/requirements.runpod.txt` (d√©pendances)
- Variables d'environnement Vast.ai (not√©es dans un endroit s√ªr)

**O√π sauvegarder :**
- ‚úÖ GitHub (d√©j√† fait si vous poussez le code)
- ‚úÖ Backup local (copie des fichiers)
- ‚úÖ Documentation (noter la configuration)

#### Plan de Reprise Apr√®s Sinistre

**Sc√©nario : Instance crash ou perdue**

**Temps de r√©cup√©ration estim√© :** 20-30 minutes

**√âtapes :**
1. Cr√©er nouvelle instance Vast.ai (5 min)
2. Configurer identique √† l'ancienne (5 min)
3. D√©ployer depuis GitHub (10-15 min)
4. Tester les endpoints (2 min)
5. Mettre √† jour le frontend si URL change (2 min)

**Documentation :**
- Noter l'URL de backup si vous cr√©ez une instance de secours
- Garder une copie de la configuration Vast.ai

### 4. Mises √† Jour de S√©curit√©

#### D√©pendances Python

**V√©rification r√©guli√®re :**
```bash
# V√©rifier les vuln√©rabilit√©s
pip-audit -r requirements.runpod.txt

# Mettre √† jour les d√©pendances
pip list --outdated
```

**Fr√©quence :** Mensuelle minimum

**Outils :**
- `pip-audit` : Scan des CVE
- `safety` : Alternative √† pip-audit
- GitHub Dependabot : Alertes automatiques (si repo GitHub)

#### Mises √† Jour du Mod√®le

**Quand mettre √† jour :**
- Nouvelle version du LoRA adapter
- Am√©lioration du prompt syst√®me
- Correction de bugs

**Proc√©dure :**
1. Tester localement d'abord
2. Commit et push sur GitHub
3. Red√©marrer l'instance Vast.ai
4. V√©rifier que tout fonctionne

### 5. Rotation des Secrets

#### Token Hugging Face

**Fr√©quence :** Tous les 90 jours minimum

**Proc√©dure :**
1. Cr√©er nouveau token sur https://huggingface.co/settings/tokens
2. Mettre √† jour variable d'environnement Vast.ai
3. Red√©marrer l'instance
4. V√©rifier que tout fonctionne
5. R√©voquer l'ancien token (apr√®s v√©rification)

### 6. Documentation des Incidents

#### Template d'Incident

**Cr√©er un fichier :** `docs/logs/incidents.md`

**Format :**
```markdown
## Incident [DATE]

**Type :** [Downtime / Erreur / S√©curit√©]
**Dur√©e :** [X minutes/heures]
**Cause :** [Description]
**Impact :** [Utilisateurs affect√©s, fonctionnalit√©s]
**R√©solution :** [Actions prises]
**Pr√©vention :** [Mesures pour √©viter r√©currence]
```

### 7. Maintenance Pr√©ventive

#### T√¢ches R√©guli√®res

**Quotidien :**
- [ ] V√©rifier que l'instance tourne (health check)
- [ ] V√©rifier les co√ªts dans le dashboard

**Hebdomadaire :**
- [ ] V√©rifier les logs pour erreurs
- [ ] Tester un dialogue complet
- [ ] V√©rifier les performances (latence)

**Mensuel :**
- [ ] Audit s√©curit√© (scan d√©pendances)
- [ ] V√©rifier rotation des secrets
- [ ] Mettre √† jour documentation si changements
- [ ] Backup de la configuration

**Trimestriel :**
- [ ] Review complet s√©curit√©
- [ ] Optimisation des co√ªts
- [ ] Mise √† jour des d√©pendances majeures

### 8. Alertes et Notifications

#### Alertes Recommand√©es

**√Ä configurer si possible :**
- Instance down (health check √©choue)
- Co√ªt d√©passant un seuil ($X/heure ou $Y/jour)
- Erreurs r√©p√©t√©es dans les logs
- Latence anormalement √©lev√©e

**Moyens :**
- Email (si Vast.ai le permet)
- Webhook (Slack, Discord, etc.)
- Script de monitoring (voir section Monitoring)

---

## üêõ Troubleshooting

### Probl√®me : Le mod√®le ne charge pas

**Sympt√¥mes :**
- Erreur `ValueError: HF_TOKEN ou HUGGINGFACE_TOKEN doit √™tre d√©fini`
- Erreur `401 Unauthorized` lors du t√©l√©chargement

**Solutions :**
1. V√©rifier que `HF_TOKEN` est bien configur√© dans les variables d'environnement Vast.ai
2. V√©rifier que le token a les permissions de lecture sur Hugging Face
3. V√©rifier que le token n'a pas expir√©
4. V√©rifier les logs pour voir l'erreur exacte

**Lien v√©rification token :** https://huggingface.co/settings/tokens

### Probl√®me : L'API ne r√©pond pas

**Sympt√¥mes :**
- Timeout lors des requ√™tes
- Erreur de connexion
- 502 Bad Gateway

**Solutions :**
1. V√©rifier que l'instance est bien d√©marr√©e (status "Running")
2. V√©rifier que le port 8000 est bien expos√©
3. V√©rifier les logs pour voir si le serveur FastAPI a d√©marr√©
4. Tester avec `curl` directement depuis votre machine
5. V√©rifier l'URL publique dans le dashboard Vast.ai

**Lien dashboard :** https://vast.ai/console/instances

### Probl√®me : Erreur CORS

**Sympt√¥mes :**
- `Access to fetch at '...' from origin '...' has been blocked by CORS policy`
- Erreur dans la console du navigateur

**Solutions :**
1. V√©rifier que `allow_origins` dans `app_runpod.py` inclut votre domaine
2. Modifier `app_runpod.py` ligne 543 (voir section S√©curit√© pour d√©tails complets) :
   ```python
   allow_origins=[
       "https://fjdaz.com",
       "https://www.fjdaz.com",
       # "http://localhost:8000",  # Retirer en production
   ]
   ```
3. Commit et push sur GitHub
4. Red√©marrer l'instance Vast.ai
5. V√©rifier que l'URL backend est correcte (http vs https)
6. **V√©rifier que fjdaz.com est en HTTPS** (mixed content si HTTP frontend + HTTPS backend)

### Probl√®me : GPU non d√©tect√©

**Sympt√¥mes :**
- `gpu_available: false` dans `/health`
- Latence tr√®s √©lev√©e
- Erreur `CUDA not available`

**Solutions :**
1. V√©rifier que l'instance a bien un GPU (RTX 3090) dans le dashboard Vast.ai
2. V√©rifier les logs pour voir les erreurs CUDA
3. V√©rifier que PyTorch d√©tecte le GPU : Chercher `torch.cuda.is_available()` dans les logs
4. **V√©rifier la version CUDA** dans les logs :
   ```bash
   # Dans les logs Vast.ai, chercher :
   nvidia-smi
   # ou
   CUDA Version: X.X
   ```
5. Si probl√®me persiste, utiliser une image Docker avec CUDA explicite (voir ci-dessous)

**Note :** T4 et RTX 3090 sont tous deux support√©s par PyTorch 2.0+ et bitsandbytes 0.41.0+

**Dockerfile avec CUDA Explicite (Alternative) :**

Si le Dockerfile actuel ne fonctionne pas, cr√©er `Backend/Dockerfile.vast.cuda` :

```dockerfile
FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04

# Variables d'environnement
ENV PYTHONUNBUFFERED=1
ENV DEBIAN_FRONTEND=noninteractive

# Installer Python 3.10
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    build-essential \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Cr√©er lien symbolique python
RUN ln -s /usr/bin/python3.10 /usr/bin/python

# D√©finir le r√©pertoire de travail
WORKDIR /app

# Copier requirements.txt
COPY requirements.runpod.txt /app/requirements.txt

# Installer les d√©pendances Python
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Copier les fichiers de l'application
COPY app_runpod.py /app/app.py

# Exposer le port FastAPI
EXPOSE 8000

# Commande de d√©marrage
CMD ["python", "/app/app.py"]
```

**Utilisation :** Remplacer `Dockerfile.runpod` par `Dockerfile.vast.cuda` dans la configuration Vast.ai

### Probl√®me : Erreur de m√©moire (OOM)

**Sympt√¥mes :**
- `CUDA out of memory` dans les logs
- Crash de l'instance

**Solutions :**
1. V√©rifier que le GPU a assez de VRAM (RTX 4090 ou RTX 3090 24GB suffit)
2. R√©duire `max_new_tokens` dans `app_runpod.py` (lignes 401, 449, 489)
3. V√©rifier que la quantization 4-bit est bien activ√©e (d√©j√† fait dans le code)

### Probl√®me : Le Ma√Øathon ne fonctionne pas

**Sympt√¥mes :**
- Le score ne s'affiche pas
- L'√©valuation finale √©choue

**Solutions :**
1. V√©rifier les logs du backend (dashboard Vast.ai)
2. V√©rifier que l'endpoint `/evaluate` r√©pond correctement
3. Ouvrir la console d√©veloppeur pour voir les erreurs JavaScript
4. V√©rifier que le format des donn√©es correspond √† ce que le frontend attend
5. Tester l'endpoint `/evaluate` directement avec curl

---

## üìã Checklist Compl√®te

### Pr√©paration
- [ ] Compte Vast.ai cr√©√© : https://vast.ai/
- [ ] Token Hugging Face obtenu : https://huggingface.co/settings/tokens
- [ ] Token not√© dans un endroit s√ªr
- [ ] Fichiers v√©rifi√©s (`Dockerfile.runpod`, `app_runpod.py`, `requirements.runpod.txt`)
- [ ] (Optionnel) D√©p√¥t GitHub pr√©par√©

### Configuration Instance
- [ ] Instance Vast.ai cr√©√©e : https://vast.ai/console/create
- [ ] GPU s√©lectionn√© : **RTX 4090 ($0.29/h)** ‚≠ê‚≠ê ou **RTX 3090 ($0.20-0.40/h)** ‚≠ê (excellent si < $0.25/h)
- [ ] Dockerfile configur√© (GitHub ou direct)
- [ ] Variables d'environnement configur√©es (`HF_TOKEN`, `PORT`)
- [ ] Container Disk : 50GB minimum
- [ ] Port 8000 expos√©

### D√©ploiement
- [ ] Instance lanc√©e
- [ ] Build Docker r√©ussi (5-10 min)
- [ ] Mod√®le charg√© (10-15 min)
- [ ] Serveur FastAPI d√©marr√©
- [ ] URL publique r√©cup√©r√©e

### Tests
- [ ] Test `/health` r√©ussi
- [ ] Test `/init` r√©ussi
- [ ] Test `/chat` r√©ussi
- [ ] Test `/evaluate` r√©ussi
- [ ] Script de test automatique r√©ussi

### Frontend
- [ ] `index_spinoza.html` modifi√© (ligne 127)
- [ ] URL backend mise √† jour
- [ ] Test local r√©ussi (console sans erreurs)
- [ ] Frontend mis √† jour sur serveur (si h√©berg√©)
- [ ] Test en production r√©ussi

### Validation
- [ ] Test complet frontend + backend r√©ussi
- [ ] 5 √©changes complets fonctionnent
- [ ] Score s'affiche en temps r√©el
- [ ] √âvaluation finale fonctionne
- [ ] Message final de Spinoza s'affiche
- [ ] Titre "Ma√Øathon" et "R√©fl√©chis. Reformule. Questionne." s'affichent
- [ ] Performances v√©rifi√©es (latence acceptable)
- [ ] Stabilit√© v√©rifi√©e (plusieurs dialogues)

### Documentation
- [ ] URL Vast.ai not√©e
- [ ] Date de d√©ploiement not√©e
- [ ] Configuration document√©e

### S√©curit√© (CRITIQUE)
- [ ] CORS restreint aux domaines autoris√©s uniquement (`allow_origins` modifi√©)
- [ ] Token Hugging Face en variable d'environnement (pas hardcod√© dans le code)
- [ ] Aucun token/secret dans le code (v√©rifi√© avec `grep -r "hf_"`)
- [ ] Rate limiting activ√© sur endpoints critiques (si impl√©ment√©)
- [ ] Validation stricte des inputs utilisateur (longueur, contenu malveillant)
- [ ] HTTPS configur√© (ou reverse proxy avec HTTPS)
- [ ] Monitoring des co√ªts configur√© (alertes si disponible)
- [ ] Protection prompt injection impl√©ment√©e (si applicable)
- [ ] Logs ne contiennent pas de donn√©es sensibles (tokens, secrets)
- [ ] `.env` dans `.gitignore` (si utilis√©)

### Maintenance
- [ ] Monitoring de base configur√© (health check automatique)
- [ ] Acc√®s aux logs Vast.ai document√© et test√©
- [ ] Backup de la configuration effectu√© (code + config Vast.ai)
- [ ] Plan de reprise apr√®s sinistre document√©
- [ ] Rotation des secrets planifi√©e (token HF tous les 90 jours)
- [ ] T√¢ches de maintenance d√©finies (quotidien, hebdo, mensuel)
- [ ] Script de monitoring cr√©√© (si applicable)
- [ ] Documentation des incidents pr√©par√©e (template)

---

## üìö Ressources et Liens

### Plateformes
- **Vast.ai** : https://vast.ai/
- **Dashboard Vast.ai** : https://vast.ai/console/instances
- **Cr√©er Instance** : https://vast.ai/console/create
- **Hugging Face** : https://huggingface.co/
- **Tokens HF** : https://huggingface.co/settings/tokens
- **GitHub** : https://github.com/

### Documentation
- **Guide Vast.ai d√©taill√©** : `docs/references/vast-ai/README_VAST_AI.md`
- **Quick Start** : `docs/references/vast-ai/QUICKSTART_VAST_AI.md`
- **Guide Vast.ai** : `docs/references/vast-ai/README_VAST_AI.md`
- **Guide RunPod** : `docs/references/vast-ai/README_RUNPOD.md`
- **Guide Frontend** : `Frontend/GUIDE_UPDATE_VAST_AI.md`
- **Architecture compl√®te** : `docs/references/ARCHITECTURE_COMPLETE.md`

### Mod√®les Hugging Face
- **Mistral 7B Base** : https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
- **LoRA Spinoza** : https://huggingface.co/FJDaz/mistral-7b-philosophes-lora

### Support
- **Documentation Vast.ai** : https://docs.vast.ai/
- **Support Vast.ai** : Via dashboard ou email
- **Documentation Hugging Face** : https://huggingface.co/docs

---

## üí∞ Co√ªts et Optimisation

### Co√ªts Estim√©s

**RTX 4090 sur Vast.ai (RECOMMAND√â) :**
- **Par heure** : **$0.29** (~0.26‚Ç¨/h) ‚úÖ (tarif v√©rifi√© Janvier 2025)
- **3h de d√©mo** : **$0.87** (0.78‚Ç¨)
- **8h/jour, 22j/mois** : **$51.04** (45.94‚Ç¨)
- **~60‚Ç¨/mois** : **~230h/mois** (~7.7h/jour)
- **24/7** : **$208.80/mois** (187.92‚Ç¨)

**RTX 3090 sur Vast.ai (Alternative) :**
- **Par heure** : $0.20-0.40 (~0.18-0.36‚Ç¨/h)
- **3h de d√©mo** : $0.60-1.20 (0.54-1.08‚Ç¨)
- **8h/jour, 22j/mois** : $35.20-70.40 (31.68-63.36‚Ç¨)
- **~50‚Ç¨/mois** : **~220-280h/mois** (~7-9h/jour) selon tarif
- **24/7** : $144-288/mois (129.60-259.20‚Ç¨)

**Comparaison RTX 4090 vs RTX 3090 :**

**Diff√©rence de Performance (Inf√©rence LLM) :**
- **RTX 4090** : ~50-70% plus rapide que RTX 3090 pour l'inf√©rence
- **RTX 3090** : Performance d√©j√† excellente (2-3x plus rapide que T4)

**Exemples Concrets de Latence (Mistral 7B 4-bit) :**
| Op√©ration | T4 (Colab) | RTX 3090 | RTX 4090 |
|-----------|------------|----------|----------|
| **Inf√©rence dialogue** | 2-5s | 1-3s | **0.7-1.5s** |
| **√âvaluation finale** | 5-10s | 3-6s | **2-4s** |
| **Latence totale** | 8-16s | 4-9s | **2.7-5.5s** |

**Diff√©rence RTX 4090 vs RTX 3090 :**
- **Gain de temps** : ~1.3-3.5 secondes par requ√™te compl√®te
- **Pour 100 requ√™tes** : ~2-6 minutes √©conomis√©es
- **Impact utilisateur** : Perceptible mais RTX 3090 reste tr√®s fluide

**Recommandation :**
- **RTX 4090** si priorit√© performance maximale ou si RTX 3090 > $0.25/h
- **RTX 3090** si budget serr√© ou si trouv√© √† $0.20-0.25/h (√©conomies 14-31%)
- **Les deux sont d'excellentes solutions** pour Mistral 7B + LoRA

### Optimisation des Co√ªts

1. **Arr√™ter l'instance** imm√©diatement apr√®s usage
2. **Ne pas laisser tourner** en veille
3. **Utiliser un Volume Disk persistant** seulement si usage fr√©quent (co√ªt suppl√©mentaire)
4. **Monitorer les co√ªts** dans le dashboard Vast.ai
5. **Auto-sleep automatique** : Voir section ci-dessous

---

## ‚è∞ Auto-Sleep (Arr√™t Automatique)

### Principe

L'auto-sleep permet d'arr√™ter automatiquement l'instance Vast.ai apr√®s une p√©riode d'inactivit√©, √©vitant les co√ªts inutiles.

### Impl√©mentation

**Fichier :** `Backend/auto_sleep.py`

**Fonctionnement :**
1. Le script surveille l'activit√© de l'API (requ√™tes `/chat`, `/evaluate`, `/init`)
2. Chaque requ√™te met √† jour un timestamp de derni√®re activit√©
3. Si aucune activit√© pendant X minutes (d√©faut: 30 min), arr√™t de l'instance

**Configuration :**

```bash
# Lancer l'auto-sleep en arri√®re-plan
python3 Backend/auto_sleep.py --timeout 1800 --check-interval 60 &

# Options :
# --timeout : Temps d'inactivit√© avant arr√™t (d√©faut: 1800s = 30min)
# --check-interval : Fr√©quence de v√©rification (d√©faut: 60s)
```

**Exemples de timeout :**
- **15 minutes** : `--timeout 900` (usage ponctuel)
- **30 minutes** : `--timeout 1800` (d√©faut, usage normal)
- **1 heure** : `--timeout 3600` (usage prolong√©)

### Int√©gration dans Dockerfile

**Option 1 : Lancer auto-sleep au d√©marrage**

Ajouter dans `Dockerfile.runpod` :

```dockerfile
# Copier le script auto-sleep
COPY auto_sleep.py /app/auto_sleep.py

# Lancer auto-sleep en arri√®re-plan au d√©marrage
CMD python3 /app/auto_sleep.py --timeout 1800 & python3 /app/app.py
```

**Option 2 : Utiliser un script de d√©marrage**

Cr√©er `start.sh` :

```bash
#!/bin/bash
# Lancer auto-sleep en arri√®re-plan
python3 /app/auto_sleep.py --timeout 1800 &
# Lancer FastAPI
python3 /app/app.py
```

### Limitations

‚ö†Ô∏è **Important :** Vast.ai n'a pas d'API publique pour arr√™ter automatiquement l'instance depuis le container.

**Solutions :**
1. **Arr√™t manuel** : Le script log un message, vous devez arr√™ter depuis le dashboard
2. **Webhook** : Si Vast.ai ajoute une API, utiliser un webhook pour arr√™ter l'instance
3. **Monitoring externe** : Script externe qui surveille et arr√™te via dashboard (n√©cessite authentification)

### Alternative : Monitoring Externe

Cr√©er un script externe qui :
1. V√©rifie l'activit√© via `/health` toutes les X minutes
2. Si inactif, arr√™te l'instance via l'API Vast.ai (si disponible) ou envoie une alerte

**Fichier :** `Backend/monitor_and_sleep.sh` (√† cr√©er si besoin)

---

## üöÄ Cold Start (D√©marrage √† Froid)

### Qu'est-ce que le Cold Start ?

**Cold Start = Temps d'attente avant que l'API soit pr√™te √† r√©pondre**

Quand tu d√©marres une instance Vast.ai, elle est vide. Il faut :
1. Installer les logiciels (Docker, Python, etc.)
2. T√©l√©charger le mod√®le Mistral 7B (14GB)
3. Charger le mod√®le dans la m√©moire GPU
4. D√©marrer le serveur FastAPI

**Pendant ce temps, l'API ne r√©pond pas encore !** ‚è≥

---

### Exemple Concret

**Sc√©nario :** Tu d√©marres ton instance √† 10h00 pour une d√©mo √† 10h30

**Avec Container Disk (gratuit) :**
```
10h00 ‚Üí Tu d√©marres l'instance
10h00-10h10 ‚Üí Build Docker (installation logiciels)
10h10-10h25 ‚Üí T√©l√©chargement Mistral 7B (14GB depuis internet)
10h25-10h27 ‚Üí Chargement dans GPU
10h27 ‚Üí ‚úÖ API pr√™te !
```
**Total : 27 minutes d'attente** ‚è±Ô∏è

**Avec Volume Disk (+$0.10-0.20/h) :**
```
10h00 ‚Üí Tu d√©marres l'instance
10h00-10h10 ‚Üí Build Docker (installation logiciels)
10h10 ‚Üí Mod√®le d√©j√† pr√©sent (pas de t√©l√©chargement) ‚úÖ
10h10-10h12 ‚Üí Chargement dans GPU
10h12 ‚Üí ‚úÖ API pr√™te !
```
**Total : 12 minutes d'attente** ‚è±Ô∏è

**Gain : 15 minutes √©conomis√©es !**

---

### Comparaison Simple

| Type Stockage | Co√ªt | Temps Cold Start | Quand utiliser ? |
|---------------|------|------------------|-----------------|
| **Container Disk** | Gratuit | **16-27 min** | Usage ponctuel (1-2h puis arr√™t) |
| **Volume Disk** | +$0.10-0.20/h | **6-12 min** | Usage fr√©quent (plusieurs fois/jour) |

---

### Pourquoi cette Diff√©rence ?

**Container Disk (gratuit) :**
- Stockage temporaire, effac√© √† l'arr√™t
- √Ä chaque d√©marrage ‚Üí **ret√©l√©charger le mod√®le** (14GB)
- Comme si tu r√©installais Windows √† chaque fois que tu allumes ton PC

**Volume Disk (payant) :**
- Stockage permanent, conserv√© entre red√©marrages
- Le mod√®le reste sur le disque
- Comme un disque dur externe : les fichiers restent m√™me si tu √©teins

---

### Quand Choisir Volume Disk ?

**Volume Disk est rentable si :**
- Tu red√©marres l'instance **plusieurs fois par jour**
- Tu utilises l'instance **> 4h/jour**
- Le gain de temps (15 min √ó nombre de red√©marrages) vaut le co√ªt suppl√©mentaire

**Exemple de calcul :**
- 2 red√©marrages/jour √ó 15 min √©conomis√©es = **30 min/jour**
- Volume Disk : +$0.15/h √ó 8h = **$1.20/jour**
- Si tu gagnes 30 min/jour, √ßa vaut ~$0.50-1.00 selon ta valeur du temps
- **‚Üí Volume Disk rentable si tu red√©marres souvent**

**Container Disk est suffisant si :**
- Tu d√©marres l'instance **1 fois par jour** (ou moins)
- Tu l'utilises **quelques heures puis tu l'arr√™tes**
- Tu pr√©f√®res √©conomiser $0.10-0.20/h

---

### R√©sum√© Ultra-Simple

**Cold Start = Temps d'attente au d√©marrage**

- **Container Disk** : 16-27 min (gratuit, mais lent)
- **Volume Disk** : 6-12 min (payant, mais rapide)

**Recommandation :**
- **D√©mo ponctuelle** ‚Üí Container Disk OK (attendre 20-30 min une fois)
- **Usage quotidien** ‚Üí Volume Disk (gagner 15 min √† chaque d√©marrage)

### Comparaison avec Colab

| Crit√®re | Colab | Vast.ai RTX 4090 | Vast.ai RTX 3090 |
|---------|-------|------------------|------------------|
| **Co√ªt** | Gratuit* | **$0.29/h** ‚úÖ | **$0.20-0.40/h** ‚úÖ |
| **Stabilit√©** | ‚ö†Ô∏è Instable | ‚úÖ Stable | ‚úÖ Stable |
| **Performance** | T4 (baseline) | **3-4x plus rapide** | **2-3x plus rapide** ‚úÖ |
| **VRAM** | 16GB | 24GB | 24GB ‚úÖ |
| **URL** | Change √† chaque session | ‚úÖ Fixe | ‚úÖ Fixe |
| **Contr√¥le** | Limit√© | ‚úÖ Total | ‚úÖ Total |
| **Recommandation** | - | ‚≠ê‚≠ê Meilleure perf | ‚≠ê Excellent si < $0.25/h |

*Colab : Gratuit mais avec limitations, timeout, instabilit√©

---

## üéØ Prochaines √âtapes

### Apr√®s Migration R√©ussie

1. **Monitorer les performances** pendant quelques jours
2. **Optimiser la latence** si n√©cessaire (voir optimisations possibles)
3. **Documenter les co√ªts r√©els** vs estim√©s
4. **Mettre √† jour la documentation** avec l'URL finale
5. **Informer les utilisateurs** du changement (si n√©cessaire)

### Am√©liorations Futures

1. **Volume Disk persistant** : √âviter de ret√©l√©charger le mod√®le (voir calcul rentabilit√© section 3.5)
2. **Optimisations de latence** : R√©duire `max_new_tokens`, greedy decoding
3. **Monitoring** : Ajouter des m√©triques de performance
4. **Backup** : Configurer un backup de la configuration

---

## üîÑ Proc√©dures Post-D√©ploiement

### Proc√©dure de Rollback

**Sc√©nario :** Le d√©ploiement Vast.ai √©choue ou cause des probl√®mes

**Temps estim√© :** 5-10 minutes

**√âtapes :**

1. **Arr√™ter l'instance Vast.ai**
   - Dashboard ‚Üí Instance ‚Üí Stop
   - Confirmer l'arr√™t

2. **R√©tablir l'ancien backend (Colab + ngrok)**
   - Ouvrir le notebook Colab
   - Ex√©cuter les cellules dans l'ordre
   - R√©cup√©rer la nouvelle URL ngrok

3. **Mettre √† jour le frontend**
   - Modifier `Frontend/index_spinoza.html` ligne 127
   - Remplacer URL Vast.ai par URL ngrok
   - Tester la connexion

4. **Documenter le rollback**
   - Noter dans `docs/logs/incidents.md`
   - Identifier la cause du probl√®me
   - Planifier correction avant nouveau d√©ploiement

**Note :** Garder l'instance Vast.ai arr√™t√©e (pas supprim√©e) pour investigation

### Proc√©dure de Migration GPU

**Sc√©nario :** Passer de RTX 3090 √† RTX 4090 (ou autre GPU)

**Temps estim√© :** 20-30 minutes

**√âtapes :**

1. **Cr√©er nouvelle instance avec nouveau GPU**
   - Dashboard ‚Üí Create
   - S√©lectionner RTX 4090 (ou autre)
   - **Copier la configuration** de l'ancienne instance :
     - M√™me Dockerfile
     - M√™mes variables d'environnement
     - M√™me Container Disk (ou Volume Disk si utilis√©)

2. **D√©ployer et tester**
   - Suivre √©tapes 4-5 du plan principal
   - V√©rifier que tout fonctionne

3. **Mettre √† jour le frontend** (si URL change)
   - Modifier `Frontend/index_spinoza.html` ligne 127
   - Nouvelle URL Vast.ai

4. **Arr√™ter l'ancienne instance**
   - Dashboard ‚Üí Ancienne instance ‚Üí Stop
   - V√©rifier les co√ªts finaux

5. **Comparer les performances**
   - Latence avant/apr√®s
   - Co√ªts avant/apr√®s
   - Documenter les gains

**Note :** Garder l'ancienne instance arr√™t√©e 24h avant suppression (au cas o√π)

### Proc√©dure de Mise √† Jour du Code

**Sc√©nario :** Modifier le code sans tout red√©ployer

**Temps estim√© :** 10-15 minutes

**√âtapes :**

1. **Modifier le code localement**
   - Faire les changements dans `Backend/app_runpod.py` (ou autres fichiers)

2. **Tester localement** (si possible)
   - Tester les modifications
   - V√©rifier qu'il n'y a pas d'erreurs

3. **Commit et push sur GitHub**
   ```bash
   git add Backend/app_runpod.py
   git commit -m "Description des changements"
   git push origin main
   ```

4. **Red√©marrer l'instance Vast.ai**
   - Dashboard ‚Üí Instance ‚Üí Restart
   - **OU** si d√©ploiement depuis GitHub :
     - Dashboard ‚Üí Instance ‚Üí Rebuild
     - L'instance va rebuild depuis le dernier commit

5. **Attendre le red√©marrage**
   - Build : 5-10 min (si rebuild complet)
   - Chargement mod√®le : 10-15 min (si Container Disk)
   - Chargement mod√®le : 2-3 min (si Volume Disk persistant)

6. **Tester les changements**
   - Health check
   - Test d'un dialogue complet
   - V√©rifier que les modifications fonctionnent

**Note :** Si Volume Disk persistant, le mod√®le n'est pas ret√©l√©charg√© ‚Üí Gain de temps

### Proc√©dure de Test A/B (Colab vs Vast.ai)

**Sc√©nario :** Tester Vast.ai en parall√®le de Colab avant migration compl√®te

**Temps estim√© :** 30 minutes setup + tests

**√âtapes :**

1. **D√©ployer Vast.ai** (suivre plan principal)
   - Cr√©er instance Vast.ai
   - D√©ployer et tester
   - Noter l'URL Vast.ai

2. **Garder Colab actif**
   - Ne pas arr√™ter le notebook Colab
   - Garder l'URL ngrok active

3. **Modifier le frontend pour test A/B**
   - Cr√©er une version de test : `Frontend/index_spinoza_test.html`
   - Modifier ligne 127 pour pointer vers Vast.ai
   - Garder `index_spinoza.html` avec Colab

4. **Tester en parall√®le**
   - Ouvrir `index_spinoza.html` (Colab) dans un onglet
   - Ouvrir `index_spinoza_test.html` (Vast.ai) dans un autre onglet
   - Faire le m√™me dialogue sur les deux
   - Comparer :
     - Latence
     - Qualit√© des r√©ponses
     - Stabilit√©

5. **Documenter les r√©sultats**
   - Cr√©er `docs/tests/test_ab_colab_vs_vast.md`
   - Noter les diff√©rences
   - D√©cider de la migration compl√®te

6. **Apr√®s d√©cision**
   - Si Vast.ai meilleur : Migrer compl√®tement (√©tapes 6-7 du plan)
   - Si Colab meilleur : Arr√™ter instance Vast.ai, garder Colab
   - Si √©quivalent : Choisir selon co√ªts/stabilit√©

**Dur√©e recommand√©e du test :** 1-2 jours pour avoir assez de donn√©es

**Co√ªt test :** ~$5-10 (instance Vast.ai 1-2 jours)

---

## ‚úÖ Conclusion

Ce plan de migration vous guide √©tape par √©tape pour d√©ployer Spinoza Secours sur Vast.ai. 

**Temps total estim√© :** ~30-45 minutes (dont 15-20 min d'attente pour le mod√®le)

**Co√ªt estim√© :** 
- **RTX 4090 : $0.87** pour une d√©mo de 3h ‚úÖ (recommand√©)
- RTX 3090 : $0.60-1.20 pour une d√©mo de 3h

**Avantages :**
- ‚úÖ URL fixe et stable
- ‚úÖ Performance sup√©rieure (RTX 4090 : 3-4x plus rapide que T4)
- ‚úÖ Contr√¥le total
- ‚úÖ Co√ªts ma√Ætris√©s (RTX 4090 : $0.29/h v√©rifi√©)

**En cas de probl√®me :** Consulter la section Troubleshooting ou la documentation compl√®te.

---

**Derni√®re mise √† jour :** Janvier 2025  
**Version :** 1.2 (Finalis√© - V√©rifications compl√®tes)

**Documents compl√©mentaires :**
- `PLAN_MIGRATION_VAST_AI_CORRECTIONS.md` - D√©tails des corrections appliqu√©es
- `VERIFICATION_PLAN_MIGRATION.md` - Rapport de v√©rification technique compl√®te

