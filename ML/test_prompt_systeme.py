"""
Script de Test Prompt Syst√®me - Option 1
Teste le prompt syst√®me hybride SANS charger le mod√®le ni l'API
Pr√™t √† copier-coller dans Colab
"""

# =============================================================================
# IMPORTS
# =============================================================================

import re
from typing import Dict, List

# =============================================================================
# PROMPT SYST√àME HYBRIDE (depuis prompt_systeme_hybride.py)
# =============================================================================

SYSTEM_PROMPT_SPINOZA = """Tu ES Spinoza incarn√©. Tu dialogues avec un √©l√®ve de Terminale en premi√®re personne.

STYLE SPINOZIEN :
- G√©om√©trie des affects : r√©v√®le causes n√©cessaires, d√©duis
- Dieu = Nature
- Vocabulaire : conatus, affects, puissance d'agir, servitude

SCH√àMES LOGIQUES :
- Identit√© : Libert√© = Connaissance n√©cessit√©
- Causalit√© : Tout a cause n√©cessaire
- Implication : Joie ‚Üí augmentation puissance

M√âTHODE :
1. R√©v√®le n√©cessit√© causale
2. Distingue servitude (ignorance) vs libert√© (connaissance)
3. Exemples concrets modernes

TRANSITIONS (VARIE) :
- "Donc", "mais alors", "Imagine", "Cela implique"
- "Pourtant", "Sauf que", "C'est contradictoire"

R√àGLES :
- Tutoie (tu/ton/ta)
- Concis (2-3 phrases MAX)
- Questionne au lieu d'affirmer
- Ne parle JAMAIS de toi √† la 3√®me personne. Tu ES Spinoza."""

INSTRUCTIONS_CONTEXTUELLES = {
    "confusion": "L'√©l√®ve est confus ‚Üí Donne UNE analogie concr√®te simple en utilisant tes sch√®mes logiques.",
    "resistance": "L'√©l√®ve r√©siste ‚Üí R√©v√®le contradiction avec 'mais alors' et tes sch√®mes logiques.",
    "accord": "L'√©l√®ve est d'accord ‚Üí Valide puis AVANCE logiquement avec 'Donc' et tes sch√®mes logiques.",
    "neutre": "√âl√®ve neutre ‚Üí Pose question pour faire r√©fl√©chir en utilisant tes sch√®mes logiques."
}

INSTRUCTION_RAG = """
UTILISATION CONNAISSANCES :
- Tu connais l'√âthique de Spinoza
- Cite implicitement ("comme je l'ai montr√©...", "dans mon ≈ìuvre...")
- Reformule dans TON style (premi√®re personne, lyc√©en)
- Ne r√©cite pas : extrais id√©es et reformule naturellement
"""

def construire_prompt_complet(contexte: str, use_rag_instruction: bool = True) -> str:
    """
    Construit le prompt complet optimis√©
    
    Args:
        contexte: "accord", "confusion", "resistance", "neutre"
        use_rag_instruction: Si True, ajoute instructions RAG
    
    Returns:
        Prompt syst√®me complet (~250-300 tokens)
    """
    prompt = SYSTEM_PROMPT_SPINOZA
    
    # Ajouter instruction contextuelle
    if contexte in INSTRUCTIONS_CONTEXTUELLES:
        prompt += f"\n\n{INSTRUCTIONS_CONTEXTUELLES[contexte]}"
    
    # Ajouter instruction RAG (optionnel)
    if use_rag_instruction:
        prompt += f"\n\n{INSTRUCTION_RAG}"
    
    return prompt

# =============================================================================
# FONCTIONS DE TEST
# =============================================================================

def estimer_tokens(prompt: str) -> int:
    """
    Estime le nombre de tokens (approximation : 1 token ‚âà 0.75 mots)
    """
    mots = len(prompt.split())
    tokens_estimes = int(mots * 1.3)  # Approximation conservatrice
    return tokens_estimes

def valider_structure(prompt: str) -> Dict[str, bool]:
    """
    Valide que le prompt contient les √©l√©ments requis
    """
    validations = {
        "premiere_personne": "Tu ES Spinoza" in prompt or "premi√®re personne" in prompt.lower(),
        "schemes_logiques": "SCH√àMES LOGIQUES" in prompt or "sch√®mes" in prompt.lower(),
        "transitions": "mais alors" in prompt.lower() or "Donc" in prompt.lower(),
        "tutoie": "Tutoie" in prompt or "tu/ton/ta" in prompt,
        "concis": "Concis" in prompt or "2-3 phrases" in prompt,
        "questionne": "Questionne" in prompt or "question" in prompt.lower(),
        "ne_parle_pas_3eme": "Ne parle JAMAIS de toi √† la 3√®me personne" in prompt or "3√®me personne" in prompt.lower()
    }
    return validations

def afficher_prompt(contexte: str, use_rag_instruction: bool = True) -> None:
    """
    Affiche le prompt g√©n√©r√© pour un contexte donn√©
    """
    prompt = construire_prompt_complet(contexte, use_rag_instruction)
    tokens = estimer_tokens(prompt)
    validations = valider_structure(prompt)
    
    print("=" * 80)
    print(f"üìã CONTEXTE: {contexte.upper()}")
    print(f"üìä Tokens estim√©s: {tokens}")
    print(f"‚úÖ Validations: {sum(validations.values())}/{len(validations)}")
    print("=" * 80)
    print("\nüìù PROMPT G√âN√âR√â:\n")
    print(prompt)
    print("\n" + "=" * 80)
    print("\nüîç D√âTAILS VALIDATIONS:")
    for key, value in validations.items():
        status = "‚úÖ" if value else "‚ùå"
        print(f"  {status} {key}: {value}")
    print("=" * 80 + "\n")

def test_prompt_contextes(use_rag_instruction: bool = True) -> Dict[str, Dict]:
    """
    Teste le prompt syst√®me avec tous les contextes
    Retourne un dictionnaire avec les r√©sultats
    """
    contextes = ["accord", "confusion", "resistance", "neutre"]
    resultats = {}
    
    print("üß™ TEST PROMPT SYST√àME - TOUS LES CONTEXTES\n")
    print(f"RAG Instructions: {'‚úÖ Activ√©' if use_rag_instruction else '‚ùå D√©sactiv√©'}\n")
    
    for contexte in contextes:
        prompt = construire_prompt_complet(contexte, use_rag_instruction)
        tokens = estimer_tokens(prompt)
        validations = valider_structure(prompt)
        
        resultats[contexte] = {
            "prompt": prompt,
            "tokens": tokens,
            "validations": validations,
            "validations_ok": sum(validations.values()),
            "validations_total": len(validations)
        }
        
        # Afficher pour chaque contexte
        afficher_prompt(contexte, use_rag_instruction)
    
    # R√©sum√© global
    print("\n" + "=" * 80)
    print("üìä R√âSUM√â GLOBAL")
    print("=" * 80)
    print(f"{'Contexte':<15} {'Tokens':<10} {'Validations':<15}")
    print("-" * 80)
    for contexte, resultat in resultats.items():
        validations_str = f"{resultat['validations_ok']}/{resultat['validations_total']}"
        print(f"{contexte:<15} {resultat['tokens']:<10} {validations_str:<15}")
    
    tokens_moyen = sum(r['tokens'] for r in resultats.values()) / len(resultats)
    print("-" * 80)
    print(f"{'MOYENNE':<15} {int(tokens_moyen):<10}")
    print("=" * 80 + "\n")
    
    return resultats

def comparer_avec_rag(contexte: str = "confusion") -> None:
    """
    Compare le prompt avec et sans instructions RAG
    """
    print("=" * 80)
    print(f"üîÑ COMPARAISON AVEC/SANS RAG - Contexte: {contexte.upper()}")
    print("=" * 80)
    
    print("\nüìù AVEC RAG Instructions:")
    print("-" * 80)
    prompt_avec = construire_prompt_complet(contexte, use_rag_instruction=True)
    tokens_avec = estimer_tokens(prompt_avec)
    print(f"Tokens: {tokens_avec}")
    print(f"Longueur: {len(prompt_avec)} caract√®res")
    
    print("\nüìù SANS RAG Instructions:")
    print("-" * 80)
    prompt_sans = construire_prompt_complet(contexte, use_rag_instruction=False)
    tokens_sans = estimer_tokens(prompt_sans)
    print(f"Tokens: {tokens_sans}")
    print(f"Longueur: {len(prompt_sans)} caract√®res")
    
    economie = tokens_avec - tokens_sans
    print(f"\nüí∞ √âconomie sans RAG: {economie} tokens ({economie/tokens_avec*100:.1f}%)")
    print("=" * 80 + "\n")

def tester_detection_contexte() -> None:
    """
    Teste la fonction de d√©tection de contexte avec des exemples
    """
    print("=" * 80)
    print("üß™ TEST D√âTECTION CONTEXTE")
    print("=" * 80 + "\n")
    
    def detecter_contexte(user_input: str) -> str:
        """D√©tecte le contexte de la r√©ponse utilisateur"""
        text_lower = user_input.lower()
        
        # Accord
        if any(word in text_lower for word in ['oui', 'd\'accord', 'exact', 'ok', 'voil√†', 'tout √† fait']):
            return "accord"
        
        # Confusion
        if any(phrase in text_lower for phrase in ['comprends pas', 'vois pas', 'c\'est quoi', 'je sais pas', 'pourquoi', 'rapport']):
            return "confusion"
        
        # R√©sistance
        if any(word in text_lower for word in ['mais', 'non', 'pas d\'accord', 'faux', 'n\'importe quoi', 'je peux']):
            return "resistance"
        
        return "neutre"
    
    exemples = [
        ("Oui, je suis d'accord", "accord"),
        ("Je comprends pas", "confusion"),
        ("Mais non, je peux faire ce que je veux", "resistance"),
        ("La libert√© est importante", "neutre"),
        ("D'accord, mais alors...", "accord"),  # "d'accord" d√©tect√© en premier
        ("C'est quoi la causalit√© ?", "confusion"),
        ("Je ne suis pas d'accord", "resistance"),
    ]
    
    print(f"{'Message':<40} {'Contexte d√©tect√©':<20} {'Attendu':<15} {'Status'}")
    print("-" * 80)
    
    for message, attendu in exemples:
        detecte = detecter_contexte(message)
        status = "‚úÖ" if detecte == attendu else "‚ùå"
        print(f"{message:<40} {detecte:<20} {attendu:<15} {status}")
    
    print("=" * 80 + "\n")

def analyser_mots_cles(prompt: str) -> Dict[str, int]:
    """
    Analyse les mots-cl√©s importants dans le prompt
    """
    mots_cles = {
        "spinoza": prompt.lower().count("spinoza"),
        "premi√®re personne": prompt.lower().count("premi√®re personne") + prompt.lower().count("premiere personne"),
        "sch√®me": prompt.lower().count("sch√®me") + prompt.lower().count("scheme"),
        "mais alors": prompt.lower().count("mais alors"),
        "donc": prompt.lower().count("donc"),
        "tutoie": prompt.lower().count("tutoie") + prompt.lower().count("tu/ton/ta"),
        "concis": prompt.lower().count("concis"),
        "questionne": prompt.lower().count("questionne"),
    }
    return mots_cles

def analyser_prompt_detail(contexte: str) -> None:
    """
    Analyse d√©taill√©e d'un prompt pour un contexte donn√©
    """
    prompt = construire_prompt_complet(contexte, use_rag_instruction=True)
    mots_cles = analyser_mots_cles(prompt)
    
    print("=" * 80)
    print(f"üîç ANALYSE D√âTAILL√âE - Contexte: {contexte.upper()}")
    print("=" * 80)
    print(f"\nüìä Statistiques:")
    print(f"  Tokens estim√©s: {estimer_tokens(prompt)}")
    print(f"  Caract√®res: {len(prompt)}")
    print(f"  Mots: {len(prompt.split())}")
    print(f"  Lignes: {len(prompt.splitlines())}")
    
    print(f"\nüîë Mots-cl√©s:")
    for mot, count in mots_cles.items():
        if count > 0:
            print(f"  - '{mot}': {count} occurrence(s)")
    
    print(f"\nüìù Sections:")
    sections = ["STYLE SPINOZIEN", "SCH√àMES LOGIQUES", "M√âTHODE", "TRANSITIONS", "R√àGLES"]
    for section in sections:
        present = section in prompt
        print(f"  {'‚úÖ' if present else '‚ùå'} {section}")
    
    print("=" * 80 + "\n")

# =============================================================================
# EX√âCUTION
# =============================================================================

if __name__ == "__main__":
    print("üöÄ Script de Test Prompt Syst√®me - Option 1\n")
    
    # Test 1: Tous les contextes avec RAG
    print("=" * 80)
    print("TEST 1: TOUS LES CONTEXTES (avec RAG)")
    print("=" * 80 + "\n")
    resultats_avec_rag = test_prompt_contextes(use_rag_instruction=True)
    
    # Test 2: Comparaison avec/sans RAG
    print("\n" + "=" * 80)
    print("TEST 2: COMPARAISON AVEC/SANS RAG")
    print("=" * 80 + "\n")
    comparer_avec_rag("confusion")
    
    # Test 3: Tous les contextes sans RAG (si besoin)
    print("\n" + "=" * 80)
    print("TEST 3: TOUS LES CONTEXTES (sans RAG)")
    print("=" * 80 + "\n")
    resultats_sans_rag = test_prompt_contextes(use_rag_instruction=False)
    
    # Test 4: D√©tection contexte
    print("\n" + "=" * 80)
    print("TEST 4: D√âTECTION CONTEXTE")
    print("=" * 80 + "\n")
    tester_detection_contexte()
    
    # Test 5: Analyse d√©taill√©e (exemple confusion)
    print("\n" + "=" * 80)
    print("TEST 5: ANALYSE D√âTAILL√âE (exemple)")
    print("=" * 80 + "\n")
    analyser_prompt_detail("confusion")
    
    print("‚úÖ Tests termin√©s !")

# =============================================================================
# UTILISATION DANS COLAB
# =============================================================================

"""
ORDRE RECOMMAND√â DANS COLAB :

1. CELLULE 1 : Installation d√©pendances
   !pip install -q ...

2. CELLULE 2 : Imports + Prompt syst√®me (ce script)
   # Copier-coller tout ce script
   # Ex√©cuter pour tester le prompt AVANT de charger le mod√®le

3. CELLULE 3 : Chargement mod√®le
   model, tokenizer = load_model()

4. CELLULE 4 : API FastAPI + ngrok
   # Code API avec spinoza_repond() qui utilise le prompt test√©

AVANTAGE : Tester le prompt d'abord (rapide) avant de charger le mod√®le (lent)
"""

