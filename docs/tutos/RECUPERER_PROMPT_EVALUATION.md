# üîÑ Comment R√©cup√©rer PROMPT_EVALUATION si Modifi√© par Erreur

Si vous avez remplac√© par erreur `PROMPT_EVALUATION` dans votre notebook Colab, voici o√π le retrouver :

---

## üìç Emplacements

### 1. **Documentation de R√©f√©rence** (Recommand√©)

**Fichier :** `docs/tutos/cellule-maieuthon-backend.md`

Copiez tout le code de la cellule depuis ce fichier.

---

### 2. **Fichier Python Pr√™t √† Copier**

**Fichier :** `Backend/PROMPT_EVALUATION_COMPLET.py`

Ce fichier contient uniquement les prompts pour copier rapidement.

---

### 3. **Notebook Sauvegard√©**

**Fichier :** `RAG_Spinoza_secours.ipynb` ou `Backend/RAG_Spinoza_secours.ipynb`

Le notebook local contient la version sauvegard√©e.

---

## üìù Code Complet PROMPT_EVALUATION

### Prompt d'√âvaluation (JSON)

```python
PROMPT_EVALUATION = """Tu es Spinoza. Voici l'√©change complet avec un √©l√®ve :

{dialogue}

√âvalue l'√©l√®ve sur 3 crit√®res (0 √† 10) :
1. Compr√©hension de tes id√©es
2. Coop√©ration dans le dialogue
3. Progression de la pens√©e

R√©ponds STRICTEMENT au format JSON, AUCUNE prose :

{{
 "comprehension": X,
 "cooperation": Y,
 "progression": Z,
 "total": X+Y+Z
}}"""
```

### Prompt Message Final

```python
PROMPT_MESSAGE_FINAL = """Tu es Spinoza.

En t'inspirant EXCLUSIVEMENT de ton propre syst√®me philosophique (√âthique, conatus, affects, puissance d'agir, servitude vs libert√©, Dieu = Nature),

r√©dige un message bref √† l'√©l√®ve.

Structure (obligatoire) :
1. Un compliment sinc√®re li√© √† son niveau global.
2. Un conseil pr√©cis bas√© sur son crit√®re le plus faible.
3. Un surnom symbolique et positif, tir√© de ton univers conceptuel (ex: "puissance d'agir", "essence active", "affect joyeux").

Maximum 3 phrases.
Style concis, po√©tique, jamais condescendant.

Message :"""
```

---

## üéØ Emplacement dans la Cellule Colab

Le `PROMPT_EVALUATION` doit √™tre dans la **cellule Ma√Øeuthon** (apr√®s la cellule 7 FastAPI, avant le lancement serveur).

**Structure de la cellule :**

```python
# üéÆ MA√èEUTHON - Backend : √âvaluation et Message Final

from pydantic import BaseModel
import json
import re

class EvaluateRequest(BaseModel):
    dialogue: str
    score_front: int

class EvaluateResponse(BaseModel):
    score_final: int
    message_final: str
    details_model: dict

# Prompt d'√©valuation (temp√©rature basse, JSON strict)
PROMPT_EVALUATION = """..."""  # ‚Üê ICI

# Prompt message final (temp√©rature haute, cr√©ativit√©)
PROMPT_MESSAGE_FINAL = """..."""  # ‚Üê ICI

# Fonction evaluer_dialogue()
# ...
# Endpoint @app.post("/evaluate")
# ...
```

---

## ‚úÖ V√©rification

Apr√®s avoir copi√© le prompt, v√©rifiez que :
1. ‚úÖ Le prompt utilise `{dialogue}` comme placeholder
2. ‚úÖ Le format JSON utilise `{{` et `}}` (doubles accolades pour √©chapper)
3. ‚úÖ Les 3 crit√®res sont pr√©sents : comprehension, cooperation, progression
4. ‚úÖ Le champ `total` est d√©fini comme `X+Y+Z`

---

**Astuce :** Consultez `docs/tutos/cellule-maieuthon-backend.md` pour le code complet de toute la cellule Ma√Øeuthon.



