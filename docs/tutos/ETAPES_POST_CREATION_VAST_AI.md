# üöÄ √âtapes Post-Cr√©ation Instance Vast.ai

**Date :** 28 novembre 2025  
**Objectif :** V√©rifier le d√©ploiement et tester l'instance

---

## üìã Checklist Post-Cr√©ation

### Phase 1 : V√©rification D√©marrage (15-25 min)

- [ ] Instance cr√©√©e et en cours de d√©marrage
- [ ] Acc√©der aux logs de l'instance
- [ ] V√©rifier que le script On-start s'ex√©cute
- [ ] V√©rifier le clone du repository GitHub
- [ ] V√©rifier l'installation des d√©pendances
- [ ] V√©rifier le t√©l√©chargement du mod√®le Mistral 7B
- [ ] V√©rifier le chargement du mod√®le en GPU
- [ ] V√©rifier le d√©marrage du serveur FastAPI

---

## üîç √âtape 1 : Acc√©der aux Logs

### Dans le Dashboard Vast.ai

1. **Aller sur :** https://vast.ai/console/instances
2. **Cliquer** sur votre instance
3. **Section "Logs"** ou **"Console"**

### Ce que vous devriez voir

**S√©quence normale des logs :**

```
üöÄ D√©marrage Spinoza Secours sur Vast.ai...
üì• Clonage du repository GitHub...
Cloning into 'maiathon'...
üì¶ Installation des d√©pendances...
Collecting torch>=2.2.0
Collecting transformers>=4.40.0
...
Successfully installed torch transformers peft bitsandbytes...
üñ•Ô∏è GPU disponible: True
üîÑ Chargement Mistral 7B (4-bit GPU)...
Downloading model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.2G/14.2G
üîÑ Application LoRA Spinoza_Secours...
‚úÖ Mod√®le Mistral 7B + LoRA charg√©!
üöÄ D√©marrage du serveur FastAPI sur le port 8000...
INFO:     Started server process
INFO:     Uvicorn running on http://0.0.0.0:8000
```

---

## ‚è±Ô∏è Temps Estim√©s

| √âtape | Temps | Description |
|-------|-------|-------------|
| **Build container** | 5-10 min | D√©marrage du container Docker |
| **Clone repo** | 1-2 min | T√©l√©chargement depuis GitHub |
| **Install d√©pendances** | 3-5 min | Installation pip (torch, transformers, etc.) |
| **T√©l√©chargement mod√®le** | 10-15 min | Mistral 7B (~14GB) |
| **Chargement GPU** | 1-2 min | Chargement en m√©moire GPU |
| **D√©marrage FastAPI** | <1 min | Serveur d√©marre |
| **TOTAL** | **20-35 min** | Premier d√©marrage |

**‚ö†Ô∏è Note :** Les red√©marrages suivants seront plus rapides si vous utilisez Volume Disk (mod√®le conserv√©).

---

## üîç √âtape 2 : V√©rifier les Logs Critiques

### Logs √† Chercher

#### ‚úÖ Clone Repository R√©ussi
```
Cloning into 'maiathon'...
```

#### ‚úÖ D√©pendances Install√©es
```
Successfully installed torch transformers peft bitsandbytes accelerate fastapi uvicorn pydantic slowapi
```

#### ‚úÖ GPU D√©tect√©
```
üñ•Ô∏è GPU disponible: True
```

#### ‚úÖ Mod√®le T√©l√©charg√©
```
Downloading model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.2G/14.2G
```

#### ‚úÖ LoRA Appliqu√©
```
üîÑ Application LoRA Spinoza_Secours...
‚úÖ Mod√®le Mistral 7B + LoRA charg√©!
```

#### ‚úÖ Serveur D√©marr√©
```
INFO:     Uvicorn running on http://0.0.0.0:8000
```

---

## ‚ö†Ô∏è Probl√®mes Possibles

### Probl√®me 1 : Clone √âchoue

**Sympt√¥mes :**
```
fatal: could not read Username for 'https://github.com'
```

**Solution :**
- V√©rifier que le repository `FJDaz/maiathon` est public
- V√©rifier l'URL GitHub dans le script

### Probl√®me 2 : D√©pendances √âchouent

**Sympt√¥mes :**
```
ERROR: Could not find a version that satisfies the requirement torch>=2.2.0
```

**Solution :**
- V√©rifier la connexion internet
- V√©rifier que `requirements.runpod.txt` est correct

### Probl√®me 3 : GPU Non D√©tect√©

**Sympt√¥mes :**
```
üñ•Ô∏è GPU disponible: False
```

**Solution :**
- V√©rifier que l'instance a bien un GPU (RTX 4090)
- V√©rifier les drivers CUDA dans les logs

### Probl√®me 4 : Mod√®le Ne T√©l√©charge Pas

**Sympt√¥mes :**
```
Error: HF_TOKEN not found
```

**Solution :**
- V√©rifier que `HF_TOKEN` est bien configur√© dans Environment Variables
- V√©rifier que le token est valide

### Probl√®me 5 : Port Non Accessible

**Sympt√¥mes :**
```
Connection refused
```

**Solution :**
- V√©rifier que le port 8000 est bien expos√©
- V√©rifier que FastAPI d√©marre (logs)
- V√©rifier l'URL publique dans le dashboard

---

## üåê √âtape 3 : R√©cup√©rer l'URL Publique

### Dans le Dashboard Vast.ai

1. **Instance** ‚Üí **"Connect"** ou **"Public URL"**
2. **Noter l'URL** : `http://votre-instance.vast.ai:8000`

**Format d'URL typique :**
- `http://[instance-id].vast.ai:8000`
- `http://[ip-address]:8000`

---

## üß™ √âtape 4 : Tester les Endpoints

### Test 1 : Health Check

```bash
curl http://votre-instance.vast.ai:8000/health
```

**R√©ponse attendue :**
```json
{
  "status": "ok",
  "model": "Mistral 7B + LoRA",
  "gpu_available": true
}
```

### Test 2 : Init

```bash
curl http://votre-instance.vast.ai:8000/init
```

**R√©ponse attendue :**
```json
{
  "greeting": "Bonjour ! Je suis Spinoza. Discutons :\n\n**La libert√© est-elle une illusion ?**\n\nQu'en penses-tu ?",
  "history": [[null, "Bonjour ! Je suis Spinoza..."]]
}
```

### Test 3 : Chat

```bash
curl -X POST http://votre-instance.vast.ai:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Bonjour Spinoza, quest-ce que le conatus ?",
    "history": []
  }'
```

**R√©ponse attendue :**
```json
{
  "reply": "Le conatus, c'est l'effort par lequel chaque chose s'efforce de pers√©v√©rer dans son √™tre...",
  "history": [
    ["Bonjour Spinoza, quest-ce que le conatus ?", "Le conatus, c'est..."]
  ]
}
```

### Test 4 : Evaluate

```bash
curl -X POST http://votre-instance.vast.ai:8000/evaluate \
  -H "Content-Type: application/json" \
  -d '{
    "dialogue": "Spinoza: Bonjour !\n√âl√®ve: Bonjour",
    "score_front": 50
  }'
```

**R√©ponse attendue :**
```json
{
  "score_final": 65,
  "message_final": "Tu progresses, continue...",
  "details_model": {
    "comprehension": 5,
    "cooperation": 5,
    "progression": 5,
    "total": 15
  }
}
```

---

## üìù √âtape 5 : Script de Test Automatique

**Utiliser le script existant :**

```bash
cd /Users/francois-jeandazin/bergsonAndFriends/Spinoza_Secours_HF/Backend
./test_runpod_deployment.sh http://votre-instance.vast.ai:8000
```

**Ou cr√©er un script de test rapide :**

```bash
#!/bin/bash
API_URL="http://votre-instance.vast.ai:8000"

echo "üß™ Test Health Check..."
curl -s "$API_URL/health" | python3 -m json.tool

echo ""
echo "üß™ Test Init..."
curl -s "$API_URL/init" | python3 -m json.tool

echo ""
echo "üß™ Test Chat..."
curl -s -X POST "$API_URL/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Bonjour", "history": []}' | python3 -m json.tool
```

---

## üé® √âtape 6 : Mettre √† Jour le Frontend

### Fichier √† Modifier

**`Frontend/index_spinoza.html`** ligne 127

### Modification

**Avant :**
```javascript
const API_BASE_URL = "https://votre-ngrok-url.ngrok.io";
```

**Apr√®s :**
```javascript
const API_BASE_URL = "http://votre-instance.vast.ai:8000";
```

**‚ö†Ô∏è Important :** Remplacer `votre-instance.vast.ai` par votre vraie URL Vast.ai

### Tester le Frontend

1. Ouvrir `Frontend/index_spinoza.html` dans un navigateur
2. V√©rifier la console (F12) pour les erreurs
3. Tester un dialogue complet
4. V√©rifier que le score s'affiche

---

## üìä √âtape 7 : Monitoring

### V√©rifier les Performances

**Dans le dashboard Vast.ai :**
- **GPU Usage** : Devrait √™tre > 0% pendant l'inf√©rence
- **VRAM Usage** : Devrait √™tre ~6-8GB (Mistral 7B 4-bit)
- **Network** : Trafic entrant/sortant

### V√©rifier les Co√ªts

**Dans le dashboard :**
- **Co√ªt actuel** : $0.27-0.29/h (RTX 4090)
- **Temps d'ex√©cution** : Noter les heures
- **Co√ªt total** : Calculer selon usage

---

## ‚úÖ Checklist Compl√®te

### D√©ploiement
- [ ] Instance cr√©√©e
- [ ] Logs v√©rifi√©s (clone, install, mod√®le)
- [ ] Serveur FastAPI d√©marr√©
- [ ] URL publique r√©cup√©r√©e

### Tests
- [ ] Test `/health` r√©ussi
- [ ] Test `/init` r√©ussi
- [ ] Test `/chat` r√©ussi
- [ ] Test `/evaluate` r√©ussi

### Frontend
- [ ] `index_spinoza.html` modifi√© avec URL Vast.ai
- [ ] Frontend test√© dans navigateur
- [ ] Dialogue complet fonctionne
- [ ] Score s'affiche

### Documentation
- [ ] URL Vast.ai not√©e
- [ ] Date de d√©ploiement not√©e
- [ ] Configuration document√©e

---

## üîó R√©f√©rences

- **Script de test :** `Backend/test_runpod_deployment.sh`
- **Frontend guide :** `Frontend/GUIDE_UPDATE_VAST_AI.md`
- **Plan migration :** `docs/references/PLAN_MIGRATION_VAST_AI.md`

---

**‚úÖ Une fois tous les tests r√©ussis, le d√©ploiement est termin√© !**

