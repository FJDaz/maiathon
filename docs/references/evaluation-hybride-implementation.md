# üîß Impl√©mentation : √âvaluation Hybride (Fil de l'Eau + Finale)

**Date :** 21 novembre 2025  
**Objectif :** Optimiser l'inf√©rence en distribuant l'√©valuation sur le dialogue

---

## üéØ Architecture Hybride

### Principe

1. **√âvaluation incr√©mentale** (tous les 2 √©changes) : Score rapide invisible
2. **√âvaluation finale** (√©change 5) : Utilise les scores incr√©mentaux + message final

---

## üìã Impl√©mentation Backend

### 1. Nouveau Endpoint : `/evaluate/incremental`

**Ajouter dans `RAG_Spinoza_secours.ipynb` :**

```python
# Prompt √©valuation incr√©mentale (court, rapide)
PROMPT_EVALUATION_INCREMENTAL = """√âvalue rapidement (0-10) :
- Compr√©hension : Comprend-il mes id√©es ?
- Coop√©ration : Coop√®re-t-il dans le dialogue ?
- Progression : Sa pens√©e progresse-t-elle ?

Dialogue r√©cent (2 derniers √©changes) :
{dialogue_recent}

JSON strict (aucune prose) :
{{
 "comprehension": X,
 "cooperation": Y,
 "progression": Z,
 "total": X+Y+Z
}}"""

# Stockage scores incr√©mentaux (en m√©moire)
incremental_scores = {}  # {dialogue_id: [scores_√©change_2, scores_√©change_4, ...]}

@app.post("/evaluate/incremental")
def evaluate_incremental(req: EvaluateRequest):
    """
    √âvaluation l√©g√®re au fil de l'eau (tous les 2 √©changes)
    - Prompt court
    - Temp√©rature basse (0.1)
    - Max tokens r√©duit (50)
    - Pas de message final
    """
    # Extraire les 2 derniers √©changes seulement
    lines = req.dialogue.split('\n')
    recent_exchanges = '\n'.join(lines[-4:]) if len(lines) > 4 else req.dialogue
    
    prompt_eval = PROMPT_EVALUATION_INCREMENTAL.format(dialogue_recent=recent_exchanges)
    prompt_eval_formatted = f"<s>[INST] {prompt_eval} [/INST]"
    
    inputs = tokenizer(prompt_eval_formatted, return_tensors="pt").to(model.device)
    input_length = inputs['input_ids'].shape[1]
    
    # Inf√©rence rapide (temp√©rature basse, tokens r√©duits)
    with torch.autocast(device_type=device_type, dtype=dtype):
        outputs = model.generate(
            **inputs,
            max_new_tokens=50,  # Court pour rapidit√©
            temperature=0.1,    # Strict pour JSON
            top_p=0.9,
            do_sample=True,
            repetition_penalty=1.2,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id
        )
    
    new_tokens = outputs[0][input_length:]
    reponse_eval = tokenizer.decode(new_tokens, skip_special_tokens=True)
    
    # Parser JSON
    json_match = re.search(r'\{[^{}]*"comprehension"[^{}]*"cooperation"[^{}]*"progression"[^{}]*"total"[^{}]*\}', reponse_eval)
    if json_match:
        try:
            details_model = json.loads(json_match.group(0))
        except:
            details_model = {"comprehension": 5, "cooperation": 5, "progression": 5, "total": 15}
    else:
        details_model = {"comprehension": 5, "cooperation": 5, "progression": 5, "total": 15}
    
    # Stocker pour l'√©valuation finale
    dialogue_id = hash(req.dialogue)  # Simplifi√©, utiliser un vrai ID en production
    if dialogue_id not in incremental_scores:
        incremental_scores[dialogue_id] = []
    incremental_scores[dialogue_id].append(details_model)
    
    return {
        "scores": details_model,
        "exchange_count": len(incremental_scores[dialogue_id])
    }

# Modifier l'√©valuation finale pour utiliser les scores incr√©mentaux
def evaluer_dialogue(dialogue: str, score_front: int) -> dict:
    """
    √âvaluation finale optimis√©e (utilise scores incr√©mentaux si disponibles)
    """
    dialogue_id = hash(dialogue)
    
    # Si scores incr√©mentaux disponibles, les utiliser
    if dialogue_id in incremental_scores and len(incremental_scores[dialogue_id]) > 0:
        scores_inc = incremental_scores[dialogue_id]
        
        # Agr√©ger les scores incr√©mentaux (moyenne pond√©r√©e par ordre)
        n = len(scores_inc)
        weights = [i+1 for i in range(n)]  # Poids croissant (dernier √©change plus important)
        total_weight = sum(weights)
        
        details_model = {
            "comprehension": sum(s["comprehension"] * w for s, w in zip(scores_inc, weights)) / total_weight,
            "cooperation": sum(s["cooperation"] * w for s, w in zip(scores_inc, weights)) / total_weight,
            "progression": sum(s["progression"] * w for s, w in zip(scores_inc, weights)) / total_weight,
        }
        details_model["comprehension"] = int(round(details_model["comprehension"]))
        details_model["cooperation"] = int(round(details_model["cooperation"]))
        details_model["progression"] = int(round(details_model["progression"]))
        details_model["total"] = details_model["comprehension"] + details_model["cooperation"] + details_model["progression"]
        
        # Score total
        score_backend = details_model.get("total", 15)
        score_final = score_front + score_backend
        
        # Message final uniquement (pas besoin de r√©√©valuer)
        prompt_final = PROMPT_MESSAGE_FINAL
        # ... g√©n√©ration message final ...
        
        return {
            "score_final": score_final,
            "message_final": message_final,
            "details_model": details_model,
            "used_incremental": True  # Flag pour debug
        }
    
    # Sinon, √©valuation classique (fallback)
    # ... code existant ...
```

---

## üìã Impl√©mentation Frontend

### Modifier `index_spinoza.html`

```javascript
// Stockage scores incr√©mentaux
let incrementalScores = [];

// Apr√®s chaque 2 √©changes, appeler l'√©valuation incr√©mentale
async function handleIncrementalEvaluation() {
  if (exchangeCount % 2 === 0 && exchangeCount < MAX_EXCHANGES) {
    try {
      const response = await fetch(`${API_BASE_URL}/evaluate/incremental`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'ngrok-skip-browser-warning': 'true'
        },
        body: JSON.stringify({
          dialogue: dialogueText,
          score_front: scoreFront
        })
      });
      
      if (response.ok) {
        const data = await response.json();
        incrementalScores.push(data.scores);
        console.log('[MA√èEUTHON] Score incr√©mental:', data.scores);
        // NE PAS AFFICHER √† l'utilisateur (invisible)
      }
    } catch (error) {
      console.warn('[MA√èEUTHON] Erreur √©valuation incr√©mentale:', error);
      // Continuer le dialogue m√™me si √©chec
    }
  }
}

// Modifier la fonction d'envoi de message
async function sendMessage(userMessage) {
  // ... code existant ...
  
  // Apr√®s r√©ception de la r√©ponse
  updateDialogueText(userMessage, data.reply);
  
  // √âvaluation incr√©mentale (tous les 2 √©changes)
  await handleIncrementalEvaluation();
  
  // Fin du jeu si max atteint
  if (exchangeCount >= MAX_EXCHANGES) {
    setTimeout(() => endGame(), 1000);
  }
}
```

---

## ‚öñÔ∏è Arbitrage Qualit√© vs Performance

### Impact sur la Qualit√© du Dialogue

#### ‚úÖ **Aucun impact si invisible**

- √âvaluation incr√©mentale **cach√©e** √† l'√©l√®ve
- Pas de feedback visuel pendant le dialogue
- Le dialogue reste naturel et spontan√©
- Pas de changement de comportement

#### ‚ùå **Impact si visible**

- Si l'√©l√®ve voit ses scores ‚Üí changement de comportement
- Perte de spontan√©it√©
- Sur-adaptation ou r√©sistance

**Recommandation :** **Toujours invisible** pendant le dialogue.

---

### Impact sur la Performance

#### ‚úÖ **Charge distribu√©e**

- √âvaluation tous les 2 √©changes au lieu d'un pic en fin
- Prompt court (dialogue r√©cent seulement)
- Max tokens r√©duit (50 au lieu de 100-150)
- Pas de message final (gain de temps)

#### ‚ö†Ô∏è **Latence ajout√©e**

- 2-3 appels API suppl√©mentaires pendant le dialogue
- ~1-2 secondes de latence par √©valuation incr√©mentale
- Impact acceptable si inf√©rence rapide (< 1s)

**Recommandation :** Optimiser pour inf√©rence < 1s (prompt court, tokens r√©duits).

---

### Impact sur la Qualit√© d'√âvaluation

#### ‚úÖ **Meilleure d√©tection**

- D√©tection pr√©coce de probl√®mes (r√©sistance, incompr√©hension)
- Suivi de la progression en temps r√©el
- Scores agr√©g√©s plus pr√©cis (moyenne pond√©r√©e)

#### ‚úÖ **√âvaluation finale optimis√©e**

- Utilise les scores incr√©mentaux comme base
- R√©duit la charge en fin (pas besoin de r√©√©valuer tout)
- Message final uniquement si besoin

**Recommandation :** Valider la coh√©rence des scores incr√©mentaux vs finale.

---

## üìä Comparaison Avant/Apr√®s

| Crit√®re | Avant (Finale uniquement) | Apr√®s (Hybride) |
|---------|---------------------------|-----------------|
| **Charge en fin** | ‚ùå Pic √©lev√© | ‚úÖ Distribu√©e |
| **Fatigue mod√®le** | ‚ùå √âlev√©e | ‚úÖ R√©duite |
| **Qualit√© dialogue** | ‚úÖ Naturel | ‚úÖ Naturel (invisible) |
| **D√©tection pr√©coce** | ‚ùå Non | ‚úÖ Oui |
| **Latence totale** | ‚úÖ ~2s (fin) | ‚ö†Ô∏è ~5s (distribu√©e) |
| **Co√ªt GPU** | ‚úÖ 1 √©valuation | ‚ö†Ô∏è 3 √©valuations |
| **Qualit√© √©valuation** | ‚ö†Ô∏è Vue d'ensemble | ‚úÖ D√©tails + vue d'ensemble |

---

## üéØ Recommandation Finale

### ‚≠ê **Impl√©menter l'√©valuation hybride avec optimisations**

**Avantages :**
- ‚úÖ Charge distribu√©e (pas de pic en fin)
- ‚úÖ D√©tection pr√©coce de probl√®mes
- ‚úÖ Dialogue naturel pr√©serv√© (invisible)
- ‚úÖ √âvaluation finale de qualit√© (scores pr√©-calcul√©s)
- ‚úÖ R√©duction de la fatigue du mod√®le

**Risques mitig√©s :**
- ‚ö†Ô∏è Latence ‚Üí Optimiser pour < 1s par √©valuation incr√©mentale
- ‚ö†Ô∏è Co√ªt ‚Üí √âvaluations incr√©mentales l√©g√®res (prompt court, tokens r√©duits)
- ‚ö†Ô∏è Complexit√© ‚Üí Code bien structur√©, documentation claire

**Plan d'action :**
1. Impl√©menter `/evaluate/incremental` (Phase 1)
2. Modifier le frontend pour appeler tous les 2 √©changes (invisible)
3. Optimiser l'√©valuation finale pour utiliser les scores incr√©mentaux
4. Tester et calibrer
5. Mesurer les gains (charge, qualit√©, latence)

---

**Document cr√©√© le :** 21 novembre 2025

